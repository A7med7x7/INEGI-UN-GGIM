{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing & Set-up\n",
    "\n",
    "- test different models in the ensembles (random forest, xgb etc)\n",
    "- add linear model, lasso or ridge\n",
    "- normalize the data \n",
    "- removing outliers\n",
    "- target encoding based on cluster\n",
    "- psuedo labeling\n",
    "- encode the target nigga\n",
    "- train without the engineered features\n",
    "- train on subsets of data - like the first 1000\n",
    "- cluster based on target\n",
    "\n",
    "# if you faced errors: \n",
    "- reduce the number of clusters in `n_clusters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_52686/3029889080.py:57: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train.fillna(method='ffill',inplace=True)\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_52686/3029889080.py:58: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test.fillna(method='ffill',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd                                    \n",
    "import numpy as np     \n",
    "from sklearn.utils.class_weight import compute_class_weight   \n",
    "from sklearn.preprocessing import StandardScaler               \n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import mean_squared_error         \n",
    "from sklearn.model_selection import GroupKFold,KFold, TimeSeriesSplit, StratifiedGroupKFold,StratifiedKFold \n",
    "from sklearn.preprocessing import LabelEncoder         \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from matplotlib import rcParams\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import f1_score,roc_auc_score, roc_curve, auc,log_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import sys, os, contextlib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def suppress_output(): \n",
    "    with open(os.devnull, 'w') as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        old_stderr = sys.stderr\n",
    "        sys.stdout = devnull\n",
    "        sys.stderr = devnull\n",
    "        try: \n",
    "            yield\n",
    "        finally: \n",
    "            sys.stdout = old_stdout\n",
    "            sys.stderr = old_stderr\n",
    "            \n",
    "# Initialize models\n",
    "\n",
    "class CFG:\n",
    "  data_folder =\"../data/\"\n",
    "\n",
    "def reading_data(path: str) -> pd.DataFrame:\n",
    "  sample = pd.read_csv(path + \"SampleSubmission.csv\")\n",
    "  train = pd.read_csv(path + 'Train.csv')\n",
    "  test = pd.read_csv(path + 'Test.csv')\n",
    "  return sample,train,test\n",
    "\n",
    "sample,train,test = reading_data(CFG.data_folder)\n",
    "sample_id = sample['id']\n",
    "test_id = test['id']\n",
    "train_id = train['id']\n",
    "\n",
    "seed = 7 \n",
    "tiney_fraction = 1e-05\n",
    "\n",
    "#pd.options.display.max_columns = 200\n",
    "n_splits = 5\n",
    "gkf = StratifiedGroupKFold(n_splits=n_splits)\n",
    "train.fillna(method='ffill',inplace=True)\n",
    "test.fillna(method='ffill',inplace=True)\n",
    "\n",
    "misslead = [2, 12, 29, 31, 38, 77, 81, 97, 102, 115, 116, 130, 131, 133, 136, 143,\n",
    "            146, 150, 153, 171, 180, 220, 221, 225, 231, 233, 244, 249, 270, 271, 274,\n",
    "            283, 303, 343, 355, 396, 409, 417, 424, 435, 467, 470, 492, 495, 496, 515, \n",
    "            545, 551, 560, 579, 585, 586, 589, 592, 598, 611, 617, 636, 654, 656, 664, 683,\n",
    "            688, 718, 721, 726, 754, 784, 788, 806, 812, 842, 855, 857, 862, 894, 900, 904,\n",
    "            924, 947, 960, 980, 994, 1011, 1012, 1017, 1020, 1023, 1024, 1025, 1034, 1040, \n",
    "            1045, 1057, 1061, 1081, 1086, 1121, 1122, 1138, 1151, 1156, 1178, 1207, 1211, 1224, \n",
    "            1240, 1243, 1246, 1255, 1262, 1267, 1286, 1302, 1315, 1334, 1336, 1358, 1366, 1367,\n",
    "            1392, 1405, 1427, 1461, 1465, 1474, 1504, 1513, 1517, 1521, 1522, 1530, 1534, 1585, \n",
    "            1587, 1604, 1608, 1614, 1615, 1619, 1625, 1646, 1649, 1652, 1656, 1657, 1665, 1674,\n",
    "            1677, 1708, 1736, 1740, 1795, 1800, 1803, 1807, 1810, 1831, 1845, 1851, 1861, 1869,\n",
    "            1876, 1877, 1886, 1893, 1898, 1900, 1930, 1953, 1954, 1967, 1994, 1999, 2020, \n",
    "            2029, 2034, 2050, 2055, 2056, 2065, 2066, 2086, 2095, 2105, 2120, 2122]\n",
    "\n",
    "#train = train.drop(index=misslead).reset_index(drop=True)\n",
    "#test = test.drop(index=misslead).reset_index(drop=True)\n",
    "\n",
    "lgbm_model = CatBoostClassifier(random_state=seed)\n",
    "svm_model = SVC(probability=True, random_state=seed)\n",
    "knn_model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes = train['Target'].unique()\n",
    "indices_to_remove = []\n",
    "for idx in misslead:\n",
    "    target_value = train.loc[idx, 'Target']\n",
    "    other_samples = train[(train['Target'] == target_value) & (train.index != idx)]\n",
    "    if len(other_samples) > 0:\n",
    "        indices_to_remove.append(idx)\n",
    "train = train.drop(indices_to_remove)\n",
    "train_id = train['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup clusters \n",
    "kmeans = KMeans(n_clusters=2)\n",
    "\n",
    "lat_min, lat_max = 44.92469405, 45.88973369\n",
    "lon_min, lon_max = 8.736496578, 12.59068235\n",
    "\n",
    "num_clusters_lat = 6\n",
    "num_clusters_lon = 6\n",
    "lat_step = (lat_max - lat_min) / num_clusters_lat\n",
    "lon_step = (lon_max - lon_min) / num_clusters_lon\n",
    "def assign_clusters(row, lat_step, lon_step, lat_min, lon_min):\n",
    "    lat_cluster = ((row['LAT2'] - lat_min) / lat_step)\n",
    "    lon_cluster = ((row['LON1'] - lon_min) / lon_step)\n",
    "    return lat_cluster, lon_cluster\n",
    "for dataset in (train, test):\n",
    "    dataset[['lat_cluster', 'lon_cluster']] = dataset.apply(\n",
    "        assign_clusters, axis=1, result_type='expand',\n",
    "        lat_step=lat_step, lon_step=lon_step, lat_min=lat_min, lon_min=lon_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "geospatial_columns = ['LAT2', 'LON1', 'ELEV1', 'PEND1']\n",
    "geo_train_data = train[geospatial_columns]\n",
    "geo_test_data = test[geospatial_columns]\n",
    "n_clusters = 10\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=seed)\n",
    "train['Spatial_Group'] = kmeans.fit_predict(geo_train_data)\n",
    "test['Spatial_Group'] = kmeans.predict(geo_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_features(train: pd.DataFrame, test: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]: \n",
    "    train_dropped = train.drop(columns=['lat_cluster', 'Spatial_Group', 'id', 'lon_cluster'], inplace=False)\n",
    "    test_dropped = test.drop(columns=['lat_cluster', 'Spatial_Group', 'id', 'lon_cluster'], inplace=False)\n",
    "    return train_dropped, test_dropped\n",
    "\n",
    "train, test = drop_features(train, test)\n",
    "\n",
    "\n",
    "# Group VHVVD1 into quantiles\n",
    "train['VHVVD1_quantile'] = pd.qcut(train['VHVVD1'], q=5, labels=False)\n",
    "test['VHVVD1_quantile'] = pd.qcut(test['VHVVD1'], q=5, labels=False)\n",
    "\n",
    "# Target encode VHVVD1_quantile\n",
    "target_mean = train.groupby('VHVVD1_quantile')['Target'].mean()\n",
    "train['VHVVD1_target_encoded'] = train['VHVVD1_quantile'].map(target_mean)\n",
    "test['VHVVD1_target_encoded'] = test['VHVVD1_quantile'].map(target_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"train = train[train['NDVI2'] < 0.88]\\ntrain = train[train['NDVI1'] < 0.85]\\ntrain = train[train['NDVI3'] < 0.95]\\ntrain = train[train['ELEV1'] < 2400]\\ntrain = train[train['VHVVR1'] < 0.400000]\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#outliers \n",
    "\"\"\"train = train[train['NDVI2'] < 0.88]\n",
    "train = train[train['NDVI1'] < 0.85]\n",
    "train = train[train['NDVI3'] < 0.95]\n",
    "train = train[train['ELEV1'] < 2400]\n",
    "train = train[train['VHVVR1'] < 0.400000]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling\n",
    "\n",
    "\"\"\"# Save the 'Target' column\n",
    "\n",
    "train_id = train['id']\n",
    "predictive_features = ['Spatial_Group','lon_cluster','lat_cluster','NDVI1', 'NDVI2', 'NDVI3', 'NDVI4', 'ELEV1', 'PRECIPAN1', 'TMPMAX1', 'TMPMIN1', 'VHVVR1', 'VVD1', 'VHD1', 'VHVVD1', 'MNDWI1', 'NDTI1','Target']\n",
    "for df in (train,test):\n",
    "    for col in df.columns: \n",
    "        if col not in predictive_features:\n",
    "            df.drop(columns=[col],inplace=True)\n",
    "\"\"\"\n",
    "Target = train['Target']\n",
    "scaler = StandardScaler()\n",
    "train_columns = train.drop(columns='Target').columns\n",
    "test_columns = test.columns\n",
    "train_scaled = scaler.fit_transform(train.drop(columns='Target'))\n",
    "train = pd.DataFrame(train_scaled, columns=train_columns)\n",
    "train['Target'] = Target\n",
    "test_scaled = scaler.transform(test)\n",
    "test = pd.DataFrame(test_scaled, columns=test_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_52686/610108685.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train = train.fillna(method='bfill')\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_52686/610108685.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test = test.fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "train = train.fillna(method='bfill')\n",
    "test = test.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "train['Target'] = le.fit_transform(train['Target']) + 1\n",
    "np.sort(train['Target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspected_incorrect_labels = misslead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[1953, 1954, 1967, 1994, 1999, 2020, 2029, 2034, 2050, 2055, 2056, 2065, 2066, 2086, 2095, 2105, 2120, 2122] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_data_cleaned, train_target_cleaned\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Remove mislabeled samples from the training data\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m train_data_cleaned, train_target_cleaned \u001b[38;5;241m=\u001b[39m \u001b[43mremove_mislabeled_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspected_incorrect_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Train the SVM model on the cleaned data and make predictions on the test data\u001b[39;00m\n\u001b[1;32m     27\u001b[0m y_pred_cleaned \u001b[38;5;241m=\u001b[39m fit_and_predict_svm(train_data_cleaned, train_target_cleaned, test)\n",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m, in \u001b[0;36mremove_mislabeled_samples\u001b[0;34m(train_data, train_target, incorrect_indices)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_mislabeled_samples\u001b[39m(train_data, train_target, incorrect_indices):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Drop the mislabeled samples based on their indices\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     train_data_cleaned \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mincorrect_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     train_target_cleaned \u001b[38;5;241m=\u001b[39m train_target\u001b[38;5;241m.\u001b[39mdrop(index\u001b[38;5;241m=\u001b[39mincorrect_indices)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_data_cleaned, train_target_cleaned\n",
      "File \u001b[0;32m~/Downloads/computerscience/AI-Compeitions/INEGI-GCIM/vegitiables/lib/python3.11/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/computerscience/AI-Compeitions/INEGI-GCIM/vegitiables/lib/python3.11/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Downloads/computerscience/AI-Compeitions/INEGI-GCIM/vegitiables/lib/python3.11/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Downloads/computerscience/AI-Compeitions/INEGI-GCIM/vegitiables/lib/python3.11/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[1953, 1954, 1967, 1994, 1999, 2020, 2029, 2034, 2050, 2055, 2056, 2065, 2066, 2086, 2095, 2105, 2120, 2122] not found in axis'"
     ]
    }
   ],
   "source": [
    "# Weights for the SVM model only\n",
    "model_weights = {'svm': 1.0}  # Only SVM with full weight\n",
    "\n",
    "# Function to fit the SVM model and make predictions (probabilities)\n",
    "def fit_and_predict_svm(train_data, train_target, test_data):\n",
    "    # Train the SVM model\n",
    "    svm_model.fit(train_data, train_target)\n",
    "    \n",
    "    # Get predictions(probabilities) for the SVM model\n",
    "    y_pred_svm = svm_model.predict_proba(test_data)\n",
    "    \n",
    "    return y_pred_svm\n",
    "\n",
    "# Function to remove mislabeled samples before training the model\n",
    "def remove_mislabeled_samples(train_data, train_target, incorrect_indices):\n",
    "    # Drop the mislabeled samples based on their indices\n",
    "    train_data_cleaned = train_data.drop(index=incorrect_indices)\n",
    "    train_target_cleaned = train_target.drop(index=incorrect_indices)\n",
    "    \n",
    "    return train_data_cleaned, train_target_cleaned\n",
    "\n",
    "# Remove mislabeled samples from the training data\n",
    "train_data_cleaned, train_target_cleaned = remove_mislabeled_samples(train.drop(columns='Target'), train['Target'], suspected_incorrect_labels)\n",
    "\n",
    "# Train the SVM model on the cleaned data and make predictions on the test data\n",
    "y_pred_cleaned = fit_and_predict_svm(train_data_cleaned, train_target_cleaned, test)\n",
    "\n",
    "# Apply threshold and rounding\n",
    "y_pred_cleaned = np.round(y_pred_cleaned, 1)\n",
    "mask = y_pred_cleaned >= 0.85\n",
    "y_pred_cleaned[~mask] = 0\n",
    "\n",
    "# Create the submission DataFrame\n",
    "class_labels = [f\"Target{i}\" for i in range(y_pred_cleaned.shape[1])]\n",
    "sub_df = pd.DataFrame(y_pred_cleaned, columns=class_labels)\n",
    "sub_df['id'] = test_id\n",
    "sub_df = sub_df[['id'] + class_labels]\n",
    "\n",
    "# Add missing columns if necessary\n",
    "all_target_labels = [f\"Target_{i}\" for i in range(125)]  # Adjust target classes accordingly\n",
    "for col in all_target_labels:\n",
    "    if col not in sub_df.columns:\n",
    "        sub_df[col] = 0.0\n",
    "\n",
    "# Save the submission file\n",
    "value = np.array(scores).mean()\n",
    "sub_df.to_csv(f\"../submissions/submissioncat.csv\", index=False)\n",
    "\n",
    "# Output the indices of suspected mislabeled samples\n",
    "print(\"Suspected incorrect labels at indices:\", suspected_incorrect_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not your lucky day\n"
     ]
    }
   ],
   "source": [
    "for col in sub_df.columns:\n",
    "    if (pd.to_numeric(sub_df[col], errors='coerce') > 0.0).any():\n",
    "        print('hell yeah, finally no zero outputs')\n",
    "    else: \n",
    "        print('not your lucky day')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target\n",
      "23    143\n",
      "15    137\n",
      "34    108\n",
      "31    106\n",
      "14     93\n",
      "30     89\n",
      "27     86\n",
      "12     81\n",
      "11     78\n",
      "8      75\n",
      "37     73\n",
      "26     73\n",
      "0      66\n",
      "5      62\n",
      "36     62\n",
      "20     59\n",
      "33     58\n",
      "17     49\n",
      "9      46\n",
      "38     43\n",
      "24     42\n",
      "18     42\n",
      "41     36\n",
      "6      28\n",
      "22     25\n",
      "16     23\n",
      "3      23\n",
      "28     19\n",
      "2      18\n",
      "21     16\n",
      "4      13\n",
      "32     11\n",
      "13      8\n",
      "42      8\n",
      "40      8\n",
      "35      7\n",
      "25      6\n",
      "39      4\n",
      "43      3\n",
      "1       2\n",
      "7       2\n",
      "10      2\n",
      "19      1\n",
      "44      1\n",
      "29      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_target_cleaned.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.081838\n",
      "0:\tlearn: 3.7558541\ttotal: 309ms\tremaining: 5m 9s\n",
      "1:\tlearn: 3.7119714\ttotal: 553ms\tremaining: 4m 36s\n",
      "2:\tlearn: 3.6740194\ttotal: 692ms\tremaining: 3m 49s\n",
      "3:\tlearn: 3.6388838\ttotal: 861ms\tremaining: 3m 34s\n",
      "4:\tlearn: 3.6031879\ttotal: 1.01s\tremaining: 3m 20s\n",
      "5:\tlearn: 3.5686682\ttotal: 1.16s\tremaining: 3m 12s\n",
      "6:\tlearn: 3.5369911\ttotal: 1.31s\tremaining: 3m 5s\n",
      "7:\tlearn: 3.5058165\ttotal: 1.46s\tremaining: 3m\n",
      "8:\tlearn: 3.4736086\ttotal: 1.63s\tremaining: 2m 59s\n",
      "9:\tlearn: 3.4456295\ttotal: 1.78s\tremaining: 2m 56s\n",
      "10:\tlearn: 3.4185255\ttotal: 1.94s\tremaining: 2m 54s\n",
      "11:\tlearn: 3.3924309\ttotal: 2.1s\tremaining: 2m 53s\n",
      "12:\tlearn: 3.3678704\ttotal: 2.28s\tremaining: 2m 52s\n",
      "13:\tlearn: 3.3447309\ttotal: 2.45s\tremaining: 2m 52s\n",
      "14:\tlearn: 3.3206387\ttotal: 2.64s\tremaining: 2m 53s\n",
      "15:\tlearn: 3.2981541\ttotal: 2.84s\tremaining: 2m 54s\n",
      "16:\tlearn: 3.2767461\ttotal: 3.02s\tremaining: 2m 54s\n",
      "17:\tlearn: 3.2566827\ttotal: 3.2s\tremaining: 2m 54s\n",
      "18:\tlearn: 3.2377079\ttotal: 3.4s\tremaining: 2m 55s\n",
      "19:\tlearn: 3.2168837\ttotal: 3.74s\tremaining: 3m 3s\n",
      "20:\tlearn: 3.1986386\ttotal: 4.07s\tremaining: 3m 9s\n",
      "21:\tlearn: 3.1800599\ttotal: 4.42s\tremaining: 3m 16s\n",
      "22:\tlearn: 3.1621822\ttotal: 4.85s\tremaining: 3m 26s\n",
      "23:\tlearn: 3.1457445\ttotal: 5.2s\tremaining: 3m 31s\n",
      "24:\tlearn: 3.1287496\ttotal: 5.47s\tremaining: 3m 33s\n",
      "25:\tlearn: 3.1153861\ttotal: 5.72s\tremaining: 3m 34s\n",
      "26:\tlearn: 3.0997174\ttotal: 5.99s\tremaining: 3m 35s\n",
      "27:\tlearn: 3.0852993\ttotal: 6.26s\tremaining: 3m 37s\n",
      "28:\tlearn: 3.0728563\ttotal: 6.5s\tremaining: 3m 37s\n",
      "29:\tlearn: 3.0591232\ttotal: 6.74s\tremaining: 3m 37s\n",
      "30:\tlearn: 3.0477920\ttotal: 6.98s\tremaining: 3m 38s\n",
      "31:\tlearn: 3.0353869\ttotal: 7.22s\tremaining: 3m 38s\n",
      "32:\tlearn: 3.0225602\ttotal: 7.53s\tremaining: 3m 40s\n",
      "33:\tlearn: 3.0068884\ttotal: 7.82s\tremaining: 3m 42s\n",
      "34:\tlearn: 2.9951814\ttotal: 8.09s\tremaining: 3m 43s\n",
      "35:\tlearn: 2.9804593\ttotal: 8.36s\tremaining: 3m 43s\n",
      "36:\tlearn: 2.9687053\ttotal: 8.75s\tremaining: 3m 47s\n",
      "37:\tlearn: 2.9554524\ttotal: 9.12s\tremaining: 3m 50s\n",
      "38:\tlearn: 2.9429059\ttotal: 9.36s\tremaining: 3m 50s\n",
      "39:\tlearn: 2.9303898\ttotal: 9.69s\tremaining: 3m 52s\n",
      "40:\tlearn: 2.9205754\ttotal: 10.1s\tremaining: 3m 56s\n",
      "41:\tlearn: 2.9112295\ttotal: 10.4s\tremaining: 3m 56s\n",
      "42:\tlearn: 2.9002432\ttotal: 10.6s\tremaining: 3m 55s\n",
      "43:\tlearn: 2.8916318\ttotal: 10.8s\tremaining: 3m 54s\n",
      "44:\tlearn: 2.8813371\ttotal: 11.1s\tremaining: 3m 54s\n",
      "45:\tlearn: 2.8698377\ttotal: 11.3s\tremaining: 3m 54s\n",
      "46:\tlearn: 2.8585817\ttotal: 11.5s\tremaining: 3m 53s\n",
      "47:\tlearn: 2.8478205\ttotal: 11.8s\tremaining: 3m 53s\n",
      "48:\tlearn: 2.8378929\ttotal: 12s\tremaining: 3m 53s\n",
      "49:\tlearn: 2.8274349\ttotal: 12.3s\tremaining: 3m 53s\n",
      "50:\tlearn: 2.8155732\ttotal: 12.5s\tremaining: 3m 53s\n",
      "51:\tlearn: 2.8077988\ttotal: 12.8s\tremaining: 3m 52s\n",
      "52:\tlearn: 2.7941492\ttotal: 13s\tremaining: 3m 52s\n",
      "53:\tlearn: 2.7842374\ttotal: 13.2s\tremaining: 3m 51s\n",
      "54:\tlearn: 2.7764855\ttotal: 13.5s\tremaining: 3m 51s\n",
      "55:\tlearn: 2.7663997\ttotal: 13.7s\tremaining: 3m 50s\n",
      "56:\tlearn: 2.7577240\ttotal: 13.9s\tremaining: 3m 49s\n",
      "57:\tlearn: 2.7504305\ttotal: 14.1s\tremaining: 3m 49s\n",
      "58:\tlearn: 2.7433465\ttotal: 14.3s\tremaining: 3m 48s\n",
      "59:\tlearn: 2.7359827\ttotal: 14.5s\tremaining: 3m 47s\n",
      "60:\tlearn: 2.7264138\ttotal: 14.8s\tremaining: 3m 47s\n",
      "61:\tlearn: 2.7182435\ttotal: 15s\tremaining: 3m 47s\n",
      "62:\tlearn: 2.7113318\ttotal: 15.3s\tremaining: 3m 46s\n",
      "63:\tlearn: 2.7010757\ttotal: 15.5s\tremaining: 3m 46s\n",
      "64:\tlearn: 2.6912891\ttotal: 15.7s\tremaining: 3m 45s\n",
      "65:\tlearn: 2.6794957\ttotal: 15.9s\tremaining: 3m 45s\n",
      "66:\tlearn: 2.6710597\ttotal: 16.1s\tremaining: 3m 44s\n",
      "67:\tlearn: 2.6650416\ttotal: 16.4s\tremaining: 3m 44s\n",
      "68:\tlearn: 2.6550411\ttotal: 16.6s\tremaining: 3m 43s\n",
      "69:\tlearn: 2.6449302\ttotal: 16.8s\tremaining: 3m 43s\n",
      "70:\tlearn: 2.6332772\ttotal: 17s\tremaining: 3m 42s\n",
      "71:\tlearn: 2.6227984\ttotal: 17.2s\tremaining: 3m 42s\n",
      "72:\tlearn: 2.6163071\ttotal: 17.5s\tremaining: 3m 42s\n",
      "73:\tlearn: 2.6086750\ttotal: 17.7s\tremaining: 3m 41s\n",
      "74:\tlearn: 2.6015784\ttotal: 17.9s\tremaining: 3m 41s\n",
      "75:\tlearn: 2.5938787\ttotal: 18.2s\tremaining: 3m 41s\n",
      "76:\tlearn: 2.5867746\ttotal: 18.4s\tremaining: 3m 40s\n",
      "77:\tlearn: 2.5795232\ttotal: 18.6s\tremaining: 3m 40s\n",
      "78:\tlearn: 2.5711276\ttotal: 18.8s\tremaining: 3m 39s\n",
      "79:\tlearn: 2.5607649\ttotal: 19s\tremaining: 3m 38s\n",
      "80:\tlearn: 2.5531896\ttotal: 19.2s\tremaining: 3m 38s\n",
      "81:\tlearn: 2.5458397\ttotal: 19.4s\tremaining: 3m 37s\n",
      "82:\tlearn: 2.5385321\ttotal: 19.7s\tremaining: 3m 37s\n",
      "83:\tlearn: 2.5309902\ttotal: 19.9s\tremaining: 3m 36s\n",
      "84:\tlearn: 2.5224214\ttotal: 20.1s\tremaining: 3m 36s\n",
      "85:\tlearn: 2.5141701\ttotal: 20.3s\tremaining: 3m 35s\n",
      "86:\tlearn: 2.5051185\ttotal: 20.5s\tremaining: 3m 35s\n",
      "87:\tlearn: 2.4964056\ttotal: 20.7s\tremaining: 3m 34s\n",
      "88:\tlearn: 2.4928129\ttotal: 20.9s\tremaining: 3m 34s\n",
      "89:\tlearn: 2.4848674\ttotal: 21.1s\tremaining: 3m 33s\n",
      "90:\tlearn: 2.4779027\ttotal: 21.3s\tremaining: 3m 33s\n",
      "91:\tlearn: 2.4720862\ttotal: 21.5s\tremaining: 3m 32s\n",
      "92:\tlearn: 2.4667811\ttotal: 21.7s\tremaining: 3m 32s\n",
      "93:\tlearn: 2.4585570\ttotal: 22s\tremaining: 3m 31s\n",
      "94:\tlearn: 2.4522314\ttotal: 22.2s\tremaining: 3m 31s\n",
      "95:\tlearn: 2.4426522\ttotal: 22.4s\tremaining: 3m 30s\n",
      "96:\tlearn: 2.4365231\ttotal: 22.6s\tremaining: 3m 30s\n",
      "97:\tlearn: 2.4278557\ttotal: 22.8s\tremaining: 3m 29s\n",
      "98:\tlearn: 2.4211566\ttotal: 23s\tremaining: 3m 29s\n",
      "99:\tlearn: 2.4146468\ttotal: 23.2s\tremaining: 3m 28s\n",
      "100:\tlearn: 2.4056927\ttotal: 23.4s\tremaining: 3m 28s\n",
      "101:\tlearn: 2.3968643\ttotal: 23.6s\tremaining: 3m 27s\n",
      "102:\tlearn: 2.3922594\ttotal: 23.8s\tremaining: 3m 27s\n",
      "103:\tlearn: 2.3854705\ttotal: 24s\tremaining: 3m 26s\n",
      "104:\tlearn: 2.3808344\ttotal: 24.2s\tremaining: 3m 26s\n",
      "105:\tlearn: 2.3726255\ttotal: 24.4s\tremaining: 3m 25s\n",
      "106:\tlearn: 2.3670328\ttotal: 24.6s\tremaining: 3m 25s\n",
      "107:\tlearn: 2.3626582\ttotal: 24.8s\tremaining: 3m 25s\n",
      "108:\tlearn: 2.3550978\ttotal: 25s\tremaining: 3m 24s\n",
      "109:\tlearn: 2.3497266\ttotal: 25.2s\tremaining: 3m 23s\n",
      "110:\tlearn: 2.3462580\ttotal: 25.4s\tremaining: 3m 23s\n",
      "111:\tlearn: 2.3395517\ttotal: 25.6s\tremaining: 3m 22s\n",
      "112:\tlearn: 2.3325571\ttotal: 25.8s\tremaining: 3m 22s\n",
      "113:\tlearn: 2.3242858\ttotal: 26s\tremaining: 3m 22s\n",
      "114:\tlearn: 2.3198191\ttotal: 26.2s\tremaining: 3m 21s\n",
      "115:\tlearn: 2.3160218\ttotal: 26.4s\tremaining: 3m 21s\n",
      "116:\tlearn: 2.3126535\ttotal: 26.6s\tremaining: 3m 20s\n",
      "117:\tlearn: 2.3075219\ttotal: 26.8s\tremaining: 3m 20s\n",
      "118:\tlearn: 2.3021263\ttotal: 27s\tremaining: 3m 20s\n",
      "119:\tlearn: 2.2950970\ttotal: 27.2s\tremaining: 3m 19s\n",
      "120:\tlearn: 2.2899226\ttotal: 27.4s\tremaining: 3m 19s\n",
      "121:\tlearn: 2.2847373\ttotal: 27.6s\tremaining: 3m 18s\n",
      "122:\tlearn: 2.2810200\ttotal: 27.9s\tremaining: 3m 18s\n",
      "123:\tlearn: 2.2778733\ttotal: 28.1s\tremaining: 3m 18s\n",
      "124:\tlearn: 2.2746000\ttotal: 28.3s\tremaining: 3m 17s\n",
      "125:\tlearn: 2.2700171\ttotal: 28.5s\tremaining: 3m 17s\n",
      "126:\tlearn: 2.2664093\ttotal: 28.7s\tremaining: 3m 17s\n",
      "127:\tlearn: 2.2604929\ttotal: 28.9s\tremaining: 3m 16s\n",
      "128:\tlearn: 2.2531959\ttotal: 29.1s\tremaining: 3m 16s\n",
      "129:\tlearn: 2.2488887\ttotal: 29.3s\tremaining: 3m 16s\n",
      "130:\tlearn: 2.2444098\ttotal: 29.5s\tremaining: 3m 15s\n",
      "131:\tlearn: 2.2401514\ttotal: 29.7s\tremaining: 3m 15s\n",
      "132:\tlearn: 2.2316391\ttotal: 29.9s\tremaining: 3m 14s\n",
      "133:\tlearn: 2.2247192\ttotal: 30.1s\tremaining: 3m 14s\n",
      "134:\tlearn: 2.2176251\ttotal: 30.3s\tremaining: 3m 14s\n",
      "135:\tlearn: 2.2140004\ttotal: 30.5s\tremaining: 3m 13s\n",
      "136:\tlearn: 2.2073538\ttotal: 30.7s\tremaining: 3m 13s\n",
      "137:\tlearn: 2.2031678\ttotal: 30.9s\tremaining: 3m 12s\n",
      "138:\tlearn: 2.1977806\ttotal: 31.1s\tremaining: 3m 12s\n",
      "139:\tlearn: 2.1915032\ttotal: 31.3s\tremaining: 3m 12s\n",
      "140:\tlearn: 2.1834766\ttotal: 31.5s\tremaining: 3m 12s\n",
      "141:\tlearn: 2.1782680\ttotal: 31.7s\tremaining: 3m 11s\n",
      "142:\tlearn: 2.1712812\ttotal: 31.9s\tremaining: 3m 11s\n",
      "143:\tlearn: 2.1643157\ttotal: 32.1s\tremaining: 3m 10s\n",
      "144:\tlearn: 2.1604879\ttotal: 32.3s\tremaining: 3m 10s\n",
      "145:\tlearn: 2.1539794\ttotal: 32.5s\tremaining: 3m 10s\n",
      "146:\tlearn: 2.1520513\ttotal: 32.7s\tremaining: 3m 9s\n",
      "147:\tlearn: 2.1491969\ttotal: 32.9s\tremaining: 3m 9s\n",
      "148:\tlearn: 2.1425773\ttotal: 33.1s\tremaining: 3m 9s\n",
      "149:\tlearn: 2.1388947\ttotal: 33.3s\tremaining: 3m 8s\n",
      "150:\tlearn: 2.1360553\ttotal: 33.5s\tremaining: 3m 8s\n",
      "151:\tlearn: 2.1314653\ttotal: 33.7s\tremaining: 3m 8s\n",
      "152:\tlearn: 2.1283359\ttotal: 33.9s\tremaining: 3m 7s\n",
      "153:\tlearn: 2.1249894\ttotal: 34.1s\tremaining: 3m 7s\n",
      "154:\tlearn: 2.1211935\ttotal: 34.3s\tremaining: 3m 7s\n",
      "155:\tlearn: 2.1176875\ttotal: 34.5s\tremaining: 3m 6s\n",
      "156:\tlearn: 2.1147080\ttotal: 34.7s\tremaining: 3m 6s\n",
      "157:\tlearn: 2.1091532\ttotal: 34.9s\tremaining: 3m 6s\n",
      "158:\tlearn: 2.1063199\ttotal: 35.1s\tremaining: 3m 5s\n",
      "159:\tlearn: 2.1031808\ttotal: 35.3s\tremaining: 3m 5s\n",
      "160:\tlearn: 2.0987265\ttotal: 35.5s\tremaining: 3m 5s\n",
      "161:\tlearn: 2.0944272\ttotal: 35.7s\tremaining: 3m 4s\n",
      "162:\tlearn: 2.0905441\ttotal: 35.9s\tremaining: 3m 4s\n",
      "163:\tlearn: 2.0853561\ttotal: 36.1s\tremaining: 3m 3s\n",
      "164:\tlearn: 2.0814058\ttotal: 36.3s\tremaining: 3m 3s\n",
      "165:\tlearn: 2.0775470\ttotal: 36.5s\tremaining: 3m 3s\n",
      "166:\tlearn: 2.0739912\ttotal: 36.7s\tremaining: 3m 3s\n",
      "167:\tlearn: 2.0678407\ttotal: 36.9s\tremaining: 3m 2s\n",
      "168:\tlearn: 2.0652533\ttotal: 37.1s\tremaining: 3m 2s\n",
      "169:\tlearn: 2.0617500\ttotal: 37.3s\tremaining: 3m 1s\n",
      "170:\tlearn: 2.0570121\ttotal: 37.5s\tremaining: 3m 1s\n",
      "171:\tlearn: 2.0529869\ttotal: 37.6s\tremaining: 3m 1s\n",
      "172:\tlearn: 2.0500809\ttotal: 37.9s\tremaining: 3m\n",
      "173:\tlearn: 2.0475392\ttotal: 38.1s\tremaining: 3m\n",
      "174:\tlearn: 2.0425525\ttotal: 38.3s\tremaining: 3m\n",
      "175:\tlearn: 2.0365054\ttotal: 38.5s\tremaining: 3m\n",
      "176:\tlearn: 2.0329831\ttotal: 38.8s\tremaining: 3m\n",
      "177:\tlearn: 2.0294362\ttotal: 38.9s\tremaining: 2m 59s\n",
      "178:\tlearn: 2.0269730\ttotal: 39.1s\tremaining: 2m 59s\n",
      "179:\tlearn: 2.0221447\ttotal: 39.4s\tremaining: 2m 59s\n",
      "180:\tlearn: 2.0200638\ttotal: 39.5s\tremaining: 2m 58s\n",
      "181:\tlearn: 2.0159918\ttotal: 39.7s\tremaining: 2m 58s\n",
      "182:\tlearn: 2.0099207\ttotal: 39.9s\tremaining: 2m 58s\n",
      "183:\tlearn: 2.0086583\ttotal: 40.1s\tremaining: 2m 57s\n",
      "184:\tlearn: 2.0030212\ttotal: 40.3s\tremaining: 2m 57s\n",
      "185:\tlearn: 1.9965805\ttotal: 40.5s\tremaining: 2m 57s\n",
      "186:\tlearn: 1.9921483\ttotal: 40.7s\tremaining: 2m 56s\n",
      "187:\tlearn: 1.9881839\ttotal: 40.9s\tremaining: 2m 56s\n",
      "188:\tlearn: 1.9835690\ttotal: 41.1s\tremaining: 2m 56s\n",
      "189:\tlearn: 1.9789850\ttotal: 41.3s\tremaining: 2m 56s\n",
      "190:\tlearn: 1.9758495\ttotal: 41.5s\tremaining: 2m 55s\n",
      "191:\tlearn: 1.9706583\ttotal: 41.7s\tremaining: 2m 55s\n",
      "192:\tlearn: 1.9675510\ttotal: 41.9s\tremaining: 2m 55s\n",
      "193:\tlearn: 1.9647906\ttotal: 42.1s\tremaining: 2m 54s\n",
      "194:\tlearn: 1.9598696\ttotal: 42.3s\tremaining: 2m 54s\n",
      "195:\tlearn: 1.9540045\ttotal: 42.5s\tremaining: 2m 54s\n",
      "196:\tlearn: 1.9495907\ttotal: 42.7s\tremaining: 2m 54s\n",
      "197:\tlearn: 1.9463744\ttotal: 42.9s\tremaining: 2m 53s\n",
      "198:\tlearn: 1.9417253\ttotal: 43.1s\tremaining: 2m 53s\n",
      "199:\tlearn: 1.9386039\ttotal: 43.3s\tremaining: 2m 53s\n",
      "200:\tlearn: 1.9351859\ttotal: 43.5s\tremaining: 2m 53s\n",
      "201:\tlearn: 1.9299214\ttotal: 43.7s\tremaining: 2m 52s\n",
      "202:\tlearn: 1.9274825\ttotal: 43.9s\tremaining: 2m 52s\n",
      "203:\tlearn: 1.9219771\ttotal: 44.1s\tremaining: 2m 52s\n",
      "204:\tlearn: 1.9181465\ttotal: 44.3s\tremaining: 2m 51s\n",
      "205:\tlearn: 1.9151038\ttotal: 44.5s\tremaining: 2m 51s\n",
      "206:\tlearn: 1.9111549\ttotal: 44.7s\tremaining: 2m 51s\n",
      "207:\tlearn: 1.9086953\ttotal: 44.9s\tremaining: 2m 50s\n",
      "208:\tlearn: 1.9065491\ttotal: 45.1s\tremaining: 2m 50s\n",
      "209:\tlearn: 1.9025352\ttotal: 45.3s\tremaining: 2m 50s\n",
      "210:\tlearn: 1.8993736\ttotal: 45.5s\tremaining: 2m 50s\n",
      "211:\tlearn: 1.8966101\ttotal: 45.7s\tremaining: 2m 49s\n",
      "212:\tlearn: 1.8934284\ttotal: 45.9s\tremaining: 2m 49s\n",
      "213:\tlearn: 1.8920453\ttotal: 46.1s\tremaining: 2m 49s\n",
      "214:\tlearn: 1.8876451\ttotal: 46.3s\tremaining: 2m 48s\n",
      "215:\tlearn: 1.8814665\ttotal: 46.5s\tremaining: 2m 48s\n",
      "216:\tlearn: 1.8775933\ttotal: 46.7s\tremaining: 2m 48s\n",
      "217:\tlearn: 1.8720881\ttotal: 46.8s\tremaining: 2m 48s\n",
      "218:\tlearn: 1.8691333\ttotal: 47s\tremaining: 2m 47s\n",
      "219:\tlearn: 1.8655756\ttotal: 47.2s\tremaining: 2m 47s\n",
      "220:\tlearn: 1.8612372\ttotal: 47.4s\tremaining: 2m 47s\n",
      "221:\tlearn: 1.8582042\ttotal: 47.6s\tremaining: 2m 46s\n",
      "222:\tlearn: 1.8552853\ttotal: 47.8s\tremaining: 2m 46s\n",
      "223:\tlearn: 1.8512843\ttotal: 48s\tremaining: 2m 46s\n",
      "224:\tlearn: 1.8471802\ttotal: 48.3s\tremaining: 2m 46s\n",
      "225:\tlearn: 1.8440773\ttotal: 48.5s\tremaining: 2m 46s\n",
      "226:\tlearn: 1.8404119\ttotal: 48.7s\tremaining: 2m 45s\n",
      "227:\tlearn: 1.8372089\ttotal: 48.9s\tremaining: 2m 45s\n",
      "228:\tlearn: 1.8341871\ttotal: 49.1s\tremaining: 2m 45s\n",
      "229:\tlearn: 1.8305517\ttotal: 49.2s\tremaining: 2m 44s\n",
      "230:\tlearn: 1.8257293\ttotal: 49.4s\tremaining: 2m 44s\n",
      "231:\tlearn: 1.8237336\ttotal: 49.6s\tremaining: 2m 44s\n",
      "232:\tlearn: 1.8195394\ttotal: 49.8s\tremaining: 2m 43s\n",
      "233:\tlearn: 1.8169744\ttotal: 50s\tremaining: 2m 43s\n",
      "234:\tlearn: 1.8143512\ttotal: 50.2s\tremaining: 2m 43s\n",
      "235:\tlearn: 1.8100001\ttotal: 50.4s\tremaining: 2m 43s\n",
      "236:\tlearn: 1.8061926\ttotal: 50.6s\tremaining: 2m 42s\n",
      "237:\tlearn: 1.8007270\ttotal: 50.8s\tremaining: 2m 42s\n",
      "238:\tlearn: 1.7963965\ttotal: 51s\tremaining: 2m 42s\n",
      "239:\tlearn: 1.7919664\ttotal: 51.2s\tremaining: 2m 42s\n",
      "240:\tlearn: 1.7885112\ttotal: 51.4s\tremaining: 2m 41s\n",
      "241:\tlearn: 1.7840818\ttotal: 51.5s\tremaining: 2m 41s\n",
      "242:\tlearn: 1.7802967\ttotal: 51.7s\tremaining: 2m 41s\n",
      "243:\tlearn: 1.7767050\ttotal: 51.9s\tremaining: 2m 40s\n",
      "244:\tlearn: 1.7732008\ttotal: 52.1s\tremaining: 2m 40s\n",
      "245:\tlearn: 1.7695383\ttotal: 52.3s\tremaining: 2m 40s\n",
      "246:\tlearn: 1.7676135\ttotal: 52.5s\tremaining: 2m 39s\n",
      "247:\tlearn: 1.7643281\ttotal: 52.7s\tremaining: 2m 39s\n",
      "248:\tlearn: 1.7592161\ttotal: 52.9s\tremaining: 2m 39s\n",
      "249:\tlearn: 1.7551874\ttotal: 53.1s\tremaining: 2m 39s\n",
      "250:\tlearn: 1.7518970\ttotal: 53.3s\tremaining: 2m 38s\n",
      "251:\tlearn: 1.7497348\ttotal: 53.4s\tremaining: 2m 38s\n",
      "252:\tlearn: 1.7451974\ttotal: 53.6s\tremaining: 2m 38s\n",
      "253:\tlearn: 1.7426945\ttotal: 53.8s\tremaining: 2m 38s\n",
      "254:\tlearn: 1.7398004\ttotal: 54s\tremaining: 2m 37s\n",
      "255:\tlearn: 1.7386319\ttotal: 54.2s\tremaining: 2m 37s\n",
      "256:\tlearn: 1.7354631\ttotal: 54.4s\tremaining: 2m 37s\n",
      "257:\tlearn: 1.7330470\ttotal: 54.6s\tremaining: 2m 36s\n",
      "258:\tlearn: 1.7312524\ttotal: 54.7s\tremaining: 2m 36s\n",
      "259:\tlearn: 1.7270881\ttotal: 54.9s\tremaining: 2m 36s\n",
      "260:\tlearn: 1.7246446\ttotal: 55.2s\tremaining: 2m 36s\n",
      "261:\tlearn: 1.7190386\ttotal: 55.4s\tremaining: 2m 35s\n",
      "262:\tlearn: 1.7153628\ttotal: 55.5s\tremaining: 2m 35s\n",
      "263:\tlearn: 1.7111717\ttotal: 55.7s\tremaining: 2m 35s\n",
      "264:\tlearn: 1.7052110\ttotal: 56.1s\tremaining: 2m 35s\n",
      "265:\tlearn: 1.6999260\ttotal: 56.3s\tremaining: 2m 35s\n",
      "266:\tlearn: 1.6959139\ttotal: 56.4s\tremaining: 2m 34s\n",
      "267:\tlearn: 1.6909218\ttotal: 56.6s\tremaining: 2m 34s\n",
      "268:\tlearn: 1.6876545\ttotal: 56.8s\tremaining: 2m 34s\n",
      "269:\tlearn: 1.6824200\ttotal: 57s\tremaining: 2m 34s\n",
      "270:\tlearn: 1.6791433\ttotal: 57.2s\tremaining: 2m 33s\n",
      "271:\tlearn: 1.6771037\ttotal: 57.4s\tremaining: 2m 33s\n",
      "272:\tlearn: 1.6748084\ttotal: 57.6s\tremaining: 2m 33s\n",
      "273:\tlearn: 1.6705019\ttotal: 57.8s\tremaining: 2m 33s\n",
      "274:\tlearn: 1.6676757\ttotal: 58s\tremaining: 2m 32s\n",
      "275:\tlearn: 1.6643818\ttotal: 58.2s\tremaining: 2m 32s\n",
      "276:\tlearn: 1.6605524\ttotal: 58.4s\tremaining: 2m 32s\n",
      "277:\tlearn: 1.6572361\ttotal: 58.7s\tremaining: 2m 32s\n",
      "278:\tlearn: 1.6522733\ttotal: 58.8s\tremaining: 2m 32s\n",
      "279:\tlearn: 1.6468902\ttotal: 59s\tremaining: 2m 31s\n",
      "280:\tlearn: 1.6448620\ttotal: 59.2s\tremaining: 2m 31s\n",
      "281:\tlearn: 1.6405439\ttotal: 59.4s\tremaining: 2m 31s\n",
      "282:\tlearn: 1.6380128\ttotal: 59.6s\tremaining: 2m 31s\n",
      "283:\tlearn: 1.6339843\ttotal: 59.8s\tremaining: 2m 30s\n",
      "284:\tlearn: 1.6284607\ttotal: 1m\tremaining: 2m 30s\n",
      "285:\tlearn: 1.6267898\ttotal: 1m\tremaining: 2m 30s\n",
      "286:\tlearn: 1.6227281\ttotal: 1m\tremaining: 2m 30s\n",
      "287:\tlearn: 1.6169393\ttotal: 1m\tremaining: 2m 29s\n",
      "288:\tlearn: 1.6111993\ttotal: 1m\tremaining: 2m 29s\n",
      "289:\tlearn: 1.6076278\ttotal: 1m\tremaining: 2m 29s\n",
      "290:\tlearn: 1.6014653\ttotal: 1m 1s\tremaining: 2m 29s\n",
      "291:\tlearn: 1.5978791\ttotal: 1m 1s\tremaining: 2m 28s\n",
      "292:\tlearn: 1.5959269\ttotal: 1m 1s\tremaining: 2m 28s\n",
      "293:\tlearn: 1.5946977\ttotal: 1m 1s\tremaining: 2m 28s\n",
      "294:\tlearn: 1.5912922\ttotal: 1m 1s\tremaining: 2m 27s\n",
      "295:\tlearn: 1.5882548\ttotal: 1m 2s\tremaining: 2m 27s\n",
      "296:\tlearn: 1.5866726\ttotal: 1m 2s\tremaining: 2m 27s\n",
      "297:\tlearn: 1.5827551\ttotal: 1m 2s\tremaining: 2m 27s\n",
      "298:\tlearn: 1.5801789\ttotal: 1m 2s\tremaining: 2m 27s\n",
      "299:\tlearn: 1.5773761\ttotal: 1m 2s\tremaining: 2m 26s\n",
      "300:\tlearn: 1.5720975\ttotal: 1m 3s\tremaining: 2m 26s\n",
      "301:\tlearn: 1.5708114\ttotal: 1m 3s\tremaining: 2m 26s\n",
      "302:\tlearn: 1.5675306\ttotal: 1m 3s\tremaining: 2m 25s\n",
      "303:\tlearn: 1.5619556\ttotal: 1m 3s\tremaining: 2m 25s\n",
      "304:\tlearn: 1.5593220\ttotal: 1m 3s\tremaining: 2m 25s\n",
      "305:\tlearn: 1.5548436\ttotal: 1m 4s\tremaining: 2m 25s\n",
      "306:\tlearn: 1.5532263\ttotal: 1m 4s\tremaining: 2m 24s\n",
      "307:\tlearn: 1.5487382\ttotal: 1m 4s\tremaining: 2m 24s\n",
      "308:\tlearn: 1.5427671\ttotal: 1m 4s\tremaining: 2m 24s\n",
      "309:\tlearn: 1.5364736\ttotal: 1m 4s\tremaining: 2m 24s\n",
      "310:\tlearn: 1.5319064\ttotal: 1m 5s\tremaining: 2m 24s\n",
      "311:\tlearn: 1.5264720\ttotal: 1m 5s\tremaining: 2m 24s\n",
      "312:\tlearn: 1.5231107\ttotal: 1m 5s\tremaining: 2m 23s\n",
      "313:\tlearn: 1.5216099\ttotal: 1m 5s\tremaining: 2m 23s\n",
      "314:\tlearn: 1.5197109\ttotal: 1m 5s\tremaining: 2m 23s\n",
      "315:\tlearn: 1.5167672\ttotal: 1m 6s\tremaining: 2m 23s\n",
      "316:\tlearn: 1.5137666\ttotal: 1m 6s\tremaining: 2m 22s\n",
      "317:\tlearn: 1.5099022\ttotal: 1m 6s\tremaining: 2m 22s\n",
      "318:\tlearn: 1.5047666\ttotal: 1m 6s\tremaining: 2m 22s\n",
      "319:\tlearn: 1.5020230\ttotal: 1m 6s\tremaining: 2m 22s\n",
      "320:\tlearn: 1.4997262\ttotal: 1m 7s\tremaining: 2m 21s\n",
      "321:\tlearn: 1.4965948\ttotal: 1m 7s\tremaining: 2m 21s\n",
      "322:\tlearn: 1.4934222\ttotal: 1m 7s\tremaining: 2m 21s\n",
      "323:\tlearn: 1.4889387\ttotal: 1m 7s\tremaining: 2m 21s\n",
      "324:\tlearn: 1.4865143\ttotal: 1m 7s\tremaining: 2m 20s\n",
      "325:\tlearn: 1.4839525\ttotal: 1m 8s\tremaining: 2m 20s\n",
      "326:\tlearn: 1.4798634\ttotal: 1m 8s\tremaining: 2m 20s\n",
      "327:\tlearn: 1.4769176\ttotal: 1m 8s\tremaining: 2m 20s\n",
      "328:\tlearn: 1.4745031\ttotal: 1m 8s\tremaining: 2m 20s\n",
      "329:\tlearn: 1.4708228\ttotal: 1m 8s\tremaining: 2m 19s\n",
      "330:\tlearn: 1.4654399\ttotal: 1m 9s\tremaining: 2m 19s\n",
      "331:\tlearn: 1.4627018\ttotal: 1m 9s\tremaining: 2m 19s\n",
      "332:\tlearn: 1.4609093\ttotal: 1m 9s\tremaining: 2m 19s\n",
      "333:\tlearn: 1.4581064\ttotal: 1m 9s\tremaining: 2m 18s\n",
      "334:\tlearn: 1.4531076\ttotal: 1m 9s\tremaining: 2m 18s\n",
      "335:\tlearn: 1.4484164\ttotal: 1m 10s\tremaining: 2m 18s\n",
      "336:\tlearn: 1.4451636\ttotal: 1m 10s\tremaining: 2m 18s\n",
      "337:\tlearn: 1.4418284\ttotal: 1m 10s\tremaining: 2m 17s\n",
      "338:\tlearn: 1.4401530\ttotal: 1m 10s\tremaining: 2m 17s\n",
      "339:\tlearn: 1.4383720\ttotal: 1m 10s\tremaining: 2m 17s\n",
      "340:\tlearn: 1.4362727\ttotal: 1m 11s\tremaining: 2m 17s\n",
      "341:\tlearn: 1.4352645\ttotal: 1m 11s\tremaining: 2m 16s\n",
      "342:\tlearn: 1.4318793\ttotal: 1m 11s\tremaining: 2m 16s\n",
      "343:\tlearn: 1.4273563\ttotal: 1m 11s\tremaining: 2m 16s\n",
      "344:\tlearn: 1.4264317\ttotal: 1m 11s\tremaining: 2m 16s\n",
      "345:\tlearn: 1.4211436\ttotal: 1m 12s\tremaining: 2m 16s\n",
      "346:\tlearn: 1.4188351\ttotal: 1m 12s\tremaining: 2m 15s\n",
      "347:\tlearn: 1.4158385\ttotal: 1m 12s\tremaining: 2m 15s\n",
      "348:\tlearn: 1.4127799\ttotal: 1m 12s\tremaining: 2m 15s\n",
      "349:\tlearn: 1.4077707\ttotal: 1m 12s\tremaining: 2m 15s\n",
      "350:\tlearn: 1.4052283\ttotal: 1m 12s\tremaining: 2m 14s\n",
      "351:\tlearn: 1.4042064\ttotal: 1m 13s\tremaining: 2m 14s\n",
      "352:\tlearn: 1.3997396\ttotal: 1m 13s\tremaining: 2m 14s\n",
      "353:\tlearn: 1.3955507\ttotal: 1m 13s\tremaining: 2m 14s\n",
      "354:\tlearn: 1.3925467\ttotal: 1m 13s\tremaining: 2m 13s\n",
      "355:\tlearn: 1.3897781\ttotal: 1m 13s\tremaining: 2m 13s\n",
      "356:\tlearn: 1.3879494\ttotal: 1m 14s\tremaining: 2m 13s\n",
      "357:\tlearn: 1.3854941\ttotal: 1m 14s\tremaining: 2m 13s\n",
      "358:\tlearn: 1.3838381\ttotal: 1m 14s\tremaining: 2m 13s\n",
      "359:\tlearn: 1.3814017\ttotal: 1m 14s\tremaining: 2m 12s\n",
      "360:\tlearn: 1.3793344\ttotal: 1m 14s\tremaining: 2m 12s\n",
      "361:\tlearn: 1.3759333\ttotal: 1m 15s\tremaining: 2m 12s\n",
      "362:\tlearn: 1.3716246\ttotal: 1m 15s\tremaining: 2m 12s\n",
      "363:\tlearn: 1.3681829\ttotal: 1m 15s\tremaining: 2m 11s\n",
      "364:\tlearn: 1.3660276\ttotal: 1m 15s\tremaining: 2m 11s\n",
      "365:\tlearn: 1.3621003\ttotal: 1m 15s\tremaining: 2m 11s\n",
      "366:\tlearn: 1.3590462\ttotal: 1m 16s\tremaining: 2m 11s\n",
      "367:\tlearn: 1.3539761\ttotal: 1m 16s\tremaining: 2m 10s\n",
      "368:\tlearn: 1.3494170\ttotal: 1m 16s\tremaining: 2m 10s\n",
      "369:\tlearn: 1.3461261\ttotal: 1m 16s\tremaining: 2m 10s\n",
      "370:\tlearn: 1.3429510\ttotal: 1m 16s\tremaining: 2m 10s\n",
      "371:\tlearn: 1.3395198\ttotal: 1m 17s\tremaining: 2m 10s\n",
      "372:\tlearn: 1.3345805\ttotal: 1m 17s\tremaining: 2m 9s\n",
      "373:\tlearn: 1.3320539\ttotal: 1m 17s\tremaining: 2m 9s\n",
      "374:\tlearn: 1.3305087\ttotal: 1m 17s\tremaining: 2m 9s\n",
      "375:\tlearn: 1.3286667\ttotal: 1m 17s\tremaining: 2m 9s\n",
      "376:\tlearn: 1.3262589\ttotal: 1m 18s\tremaining: 2m 8s\n",
      "377:\tlearn: 1.3227270\ttotal: 1m 18s\tremaining: 2m 8s\n",
      "378:\tlearn: 1.3202999\ttotal: 1m 18s\tremaining: 2m 8s\n",
      "379:\tlearn: 1.3165483\ttotal: 1m 18s\tremaining: 2m 8s\n",
      "380:\tlearn: 1.3115620\ttotal: 1m 18s\tremaining: 2m 8s\n",
      "381:\tlearn: 1.3089859\ttotal: 1m 19s\tremaining: 2m 8s\n",
      "382:\tlearn: 1.3064637\ttotal: 1m 19s\tremaining: 2m 7s\n",
      "383:\tlearn: 1.3036989\ttotal: 1m 19s\tremaining: 2m 7s\n",
      "384:\tlearn: 1.3020999\ttotal: 1m 19s\tremaining: 2m 7s\n",
      "385:\tlearn: 1.2965047\ttotal: 1m 19s\tremaining: 2m 7s\n",
      "386:\tlearn: 1.2927186\ttotal: 1m 20s\tremaining: 2m 6s\n",
      "387:\tlearn: 1.2906635\ttotal: 1m 20s\tremaining: 2m 6s\n",
      "388:\tlearn: 1.2870257\ttotal: 1m 20s\tremaining: 2m 6s\n",
      "389:\tlearn: 1.2830529\ttotal: 1m 20s\tremaining: 2m 6s\n",
      "390:\tlearn: 1.2811365\ttotal: 1m 20s\tremaining: 2m 6s\n",
      "391:\tlearn: 1.2777215\ttotal: 1m 21s\tremaining: 2m 5s\n",
      "392:\tlearn: 1.2741690\ttotal: 1m 21s\tremaining: 2m 5s\n",
      "393:\tlearn: 1.2704816\ttotal: 1m 21s\tremaining: 2m 5s\n",
      "394:\tlearn: 1.2671907\ttotal: 1m 21s\tremaining: 2m 5s\n",
      "395:\tlearn: 1.2635293\ttotal: 1m 21s\tremaining: 2m 5s\n",
      "396:\tlearn: 1.2610829\ttotal: 1m 22s\tremaining: 2m 4s\n",
      "397:\tlearn: 1.2580355\ttotal: 1m 22s\tremaining: 2m 4s\n",
      "398:\tlearn: 1.2552492\ttotal: 1m 22s\tremaining: 2m 4s\n",
      "399:\tlearn: 1.2525558\ttotal: 1m 22s\tremaining: 2m 4s\n",
      "400:\tlearn: 1.2515993\ttotal: 1m 23s\tremaining: 2m 3s\n",
      "401:\tlearn: 1.2480879\ttotal: 1m 23s\tremaining: 2m 3s\n",
      "402:\tlearn: 1.2440195\ttotal: 1m 23s\tremaining: 2m 3s\n",
      "403:\tlearn: 1.2401488\ttotal: 1m 23s\tremaining: 2m 3s\n",
      "404:\tlearn: 1.2371478\ttotal: 1m 23s\tremaining: 2m 3s\n",
      "405:\tlearn: 1.2348746\ttotal: 1m 24s\tremaining: 2m 2s\n",
      "406:\tlearn: 1.2312415\ttotal: 1m 24s\tremaining: 2m 2s\n",
      "407:\tlearn: 1.2283562\ttotal: 1m 24s\tremaining: 2m 2s\n",
      "408:\tlearn: 1.2262960\ttotal: 1m 24s\tremaining: 2m 2s\n",
      "409:\tlearn: 1.2236507\ttotal: 1m 24s\tremaining: 2m 2s\n",
      "410:\tlearn: 1.2196067\ttotal: 1m 25s\tremaining: 2m 2s\n",
      "411:\tlearn: 1.2178210\ttotal: 1m 25s\tremaining: 2m 1s\n",
      "412:\tlearn: 1.2145372\ttotal: 1m 25s\tremaining: 2m 1s\n",
      "413:\tlearn: 1.2129379\ttotal: 1m 25s\tremaining: 2m 1s\n",
      "414:\tlearn: 1.2112946\ttotal: 1m 26s\tremaining: 2m 1s\n",
      "415:\tlearn: 1.2085603\ttotal: 1m 26s\tremaining: 2m 1s\n",
      "416:\tlearn: 1.2062859\ttotal: 1m 26s\tremaining: 2m\n",
      "417:\tlearn: 1.2044154\ttotal: 1m 26s\tremaining: 2m\n",
      "418:\tlearn: 1.2008281\ttotal: 1m 26s\tremaining: 2m\n",
      "419:\tlearn: 1.1973996\ttotal: 1m 27s\tremaining: 2m\n",
      "420:\tlearn: 1.1949292\ttotal: 1m 27s\tremaining: 1m 59s\n",
      "421:\tlearn: 1.1926174\ttotal: 1m 27s\tremaining: 1m 59s\n",
      "422:\tlearn: 1.1905148\ttotal: 1m 27s\tremaining: 1m 59s\n",
      "423:\tlearn: 1.1880062\ttotal: 1m 28s\tremaining: 1m 59s\n",
      "424:\tlearn: 1.1853944\ttotal: 1m 28s\tremaining: 1m 59s\n",
      "425:\tlearn: 1.1825724\ttotal: 1m 28s\tremaining: 1m 59s\n",
      "426:\tlearn: 1.1818972\ttotal: 1m 28s\tremaining: 1m 59s\n",
      "427:\tlearn: 1.1792503\ttotal: 1m 29s\tremaining: 1m 59s\n",
      "428:\tlearn: 1.1767277\ttotal: 1m 29s\tremaining: 1m 58s\n",
      "429:\tlearn: 1.1750007\ttotal: 1m 29s\tremaining: 1m 58s\n",
      "430:\tlearn: 1.1734711\ttotal: 1m 29s\tremaining: 1m 58s\n",
      "431:\tlearn: 1.1711876\ttotal: 1m 30s\tremaining: 1m 58s\n",
      "432:\tlearn: 1.1684284\ttotal: 1m 30s\tremaining: 1m 58s\n",
      "433:\tlearn: 1.1665188\ttotal: 1m 30s\tremaining: 1m 57s\n",
      "434:\tlearn: 1.1627891\ttotal: 1m 30s\tremaining: 1m 57s\n",
      "435:\tlearn: 1.1608915\ttotal: 1m 30s\tremaining: 1m 57s\n",
      "436:\tlearn: 1.1595626\ttotal: 1m 31s\tremaining: 1m 57s\n",
      "437:\tlearn: 1.1575966\ttotal: 1m 31s\tremaining: 1m 57s\n",
      "438:\tlearn: 1.1551192\ttotal: 1m 31s\tremaining: 1m 56s\n",
      "439:\tlearn: 1.1529361\ttotal: 1m 31s\tremaining: 1m 56s\n",
      "440:\tlearn: 1.1504581\ttotal: 1m 31s\tremaining: 1m 56s\n",
      "441:\tlearn: 1.1472871\ttotal: 1m 32s\tremaining: 1m 56s\n",
      "442:\tlearn: 1.1436128\ttotal: 1m 32s\tremaining: 1m 55s\n",
      "443:\tlearn: 1.1415719\ttotal: 1m 32s\tremaining: 1m 55s\n",
      "444:\tlearn: 1.1391725\ttotal: 1m 32s\tremaining: 1m 55s\n",
      "445:\tlearn: 1.1372593\ttotal: 1m 32s\tremaining: 1m 55s\n",
      "446:\tlearn: 1.1352963\ttotal: 1m 33s\tremaining: 1m 55s\n",
      "447:\tlearn: 1.1336649\ttotal: 1m 33s\tremaining: 1m 54s\n",
      "448:\tlearn: 1.1317970\ttotal: 1m 33s\tremaining: 1m 54s\n",
      "449:\tlearn: 1.1302313\ttotal: 1m 33s\tremaining: 1m 54s\n",
      "450:\tlearn: 1.1275930\ttotal: 1m 33s\tremaining: 1m 54s\n",
      "451:\tlearn: 1.1267254\ttotal: 1m 33s\tremaining: 1m 53s\n",
      "452:\tlearn: 1.1235581\ttotal: 1m 34s\tremaining: 1m 53s\n",
      "453:\tlearn: 1.1204676\ttotal: 1m 34s\tremaining: 1m 53s\n",
      "454:\tlearn: 1.1185309\ttotal: 1m 34s\tremaining: 1m 53s\n",
      "455:\tlearn: 1.1177261\ttotal: 1m 34s\tremaining: 1m 53s\n",
      "456:\tlearn: 1.1159528\ttotal: 1m 34s\tremaining: 1m 52s\n",
      "457:\tlearn: 1.1148254\ttotal: 1m 35s\tremaining: 1m 52s\n",
      "458:\tlearn: 1.1125342\ttotal: 1m 35s\tremaining: 1m 52s\n",
      "459:\tlearn: 1.1102435\ttotal: 1m 35s\tremaining: 1m 52s\n",
      "460:\tlearn: 1.1070346\ttotal: 1m 35s\tremaining: 1m 51s\n",
      "461:\tlearn: 1.1054966\ttotal: 1m 35s\tremaining: 1m 51s\n",
      "462:\tlearn: 1.1033997\ttotal: 1m 36s\tremaining: 1m 51s\n",
      "463:\tlearn: 1.1012992\ttotal: 1m 36s\tremaining: 1m 51s\n",
      "464:\tlearn: 1.0981145\ttotal: 1m 36s\tremaining: 1m 50s\n",
      "465:\tlearn: 1.0955229\ttotal: 1m 36s\tremaining: 1m 50s\n",
      "466:\tlearn: 1.0916713\ttotal: 1m 36s\tremaining: 1m 50s\n",
      "467:\tlearn: 1.0889478\ttotal: 1m 37s\tremaining: 1m 50s\n",
      "468:\tlearn: 1.0871454\ttotal: 1m 37s\tremaining: 1m 50s\n",
      "469:\tlearn: 1.0849571\ttotal: 1m 37s\tremaining: 1m 49s\n",
      "470:\tlearn: 1.0830032\ttotal: 1m 37s\tremaining: 1m 49s\n",
      "471:\tlearn: 1.0806467\ttotal: 1m 37s\tremaining: 1m 49s\n",
      "472:\tlearn: 1.0787005\ttotal: 1m 38s\tremaining: 1m 49s\n",
      "473:\tlearn: 1.0772864\ttotal: 1m 38s\tremaining: 1m 48s\n",
      "474:\tlearn: 1.0753281\ttotal: 1m 38s\tremaining: 1m 48s\n",
      "475:\tlearn: 1.0715741\ttotal: 1m 38s\tremaining: 1m 48s\n",
      "476:\tlearn: 1.0701769\ttotal: 1m 38s\tremaining: 1m 48s\n",
      "477:\tlearn: 1.0688890\ttotal: 1m 39s\tremaining: 1m 48s\n",
      "478:\tlearn: 1.0668938\ttotal: 1m 39s\tremaining: 1m 47s\n",
      "479:\tlearn: 1.0648663\ttotal: 1m 39s\tremaining: 1m 47s\n",
      "480:\tlearn: 1.0639858\ttotal: 1m 39s\tremaining: 1m 47s\n",
      "481:\tlearn: 1.0604992\ttotal: 1m 39s\tremaining: 1m 47s\n",
      "482:\tlearn: 1.0587619\ttotal: 1m 40s\tremaining: 1m 47s\n",
      "483:\tlearn: 1.0551584\ttotal: 1m 40s\tremaining: 1m 46s\n",
      "484:\tlearn: 1.0525428\ttotal: 1m 40s\tremaining: 1m 46s\n",
      "485:\tlearn: 1.0498855\ttotal: 1m 40s\tremaining: 1m 46s\n",
      "486:\tlearn: 1.0480264\ttotal: 1m 40s\tremaining: 1m 46s\n",
      "487:\tlearn: 1.0472974\ttotal: 1m 40s\tremaining: 1m 45s\n",
      "488:\tlearn: 1.0449698\ttotal: 1m 41s\tremaining: 1m 45s\n",
      "489:\tlearn: 1.0421520\ttotal: 1m 41s\tremaining: 1m 45s\n",
      "490:\tlearn: 1.0392356\ttotal: 1m 41s\tremaining: 1m 45s\n",
      "491:\tlearn: 1.0365966\ttotal: 1m 41s\tremaining: 1m 45s\n",
      "492:\tlearn: 1.0353992\ttotal: 1m 41s\tremaining: 1m 44s\n",
      "493:\tlearn: 1.0337540\ttotal: 1m 42s\tremaining: 1m 44s\n",
      "494:\tlearn: 1.0299998\ttotal: 1m 42s\tremaining: 1m 44s\n",
      "495:\tlearn: 1.0283388\ttotal: 1m 42s\tremaining: 1m 44s\n",
      "496:\tlearn: 1.0268269\ttotal: 1m 42s\tremaining: 1m 43s\n",
      "497:\tlearn: 1.0233224\ttotal: 1m 42s\tremaining: 1m 43s\n",
      "498:\tlearn: 1.0213177\ttotal: 1m 43s\tremaining: 1m 43s\n",
      "499:\tlearn: 1.0186502\ttotal: 1m 43s\tremaining: 1m 43s\n",
      "500:\tlearn: 1.0172492\ttotal: 1m 43s\tremaining: 1m 43s\n",
      "501:\tlearn: 1.0155070\ttotal: 1m 43s\tremaining: 1m 42s\n",
      "502:\tlearn: 1.0116139\ttotal: 1m 43s\tremaining: 1m 42s\n",
      "503:\tlearn: 1.0085603\ttotal: 1m 44s\tremaining: 1m 42s\n",
      "504:\tlearn: 1.0070523\ttotal: 1m 44s\tremaining: 1m 42s\n",
      "505:\tlearn: 1.0055981\ttotal: 1m 44s\tremaining: 1m 42s\n",
      "506:\tlearn: 1.0033794\ttotal: 1m 44s\tremaining: 1m 41s\n",
      "507:\tlearn: 1.0017325\ttotal: 1m 44s\tremaining: 1m 41s\n",
      "508:\tlearn: 0.9993507\ttotal: 1m 45s\tremaining: 1m 41s\n",
      "509:\tlearn: 0.9965197\ttotal: 1m 45s\tremaining: 1m 41s\n",
      "510:\tlearn: 0.9953829\ttotal: 1m 45s\tremaining: 1m 40s\n",
      "511:\tlearn: 0.9930461\ttotal: 1m 45s\tremaining: 1m 40s\n",
      "512:\tlearn: 0.9905777\ttotal: 1m 45s\tremaining: 1m 40s\n",
      "513:\tlearn: 0.9890916\ttotal: 1m 46s\tremaining: 1m 40s\n",
      "514:\tlearn: 0.9856231\ttotal: 1m 46s\tremaining: 1m 40s\n",
      "515:\tlearn: 0.9844673\ttotal: 1m 46s\tremaining: 1m 39s\n",
      "516:\tlearn: 0.9825275\ttotal: 1m 46s\tremaining: 1m 39s\n",
      "517:\tlearn: 0.9807129\ttotal: 1m 46s\tremaining: 1m 39s\n",
      "518:\tlearn: 0.9794496\ttotal: 1m 47s\tremaining: 1m 39s\n",
      "519:\tlearn: 0.9769671\ttotal: 1m 47s\tremaining: 1m 39s\n",
      "520:\tlearn: 0.9743070\ttotal: 1m 47s\tremaining: 1m 38s\n",
      "521:\tlearn: 0.9724048\ttotal: 1m 47s\tremaining: 1m 38s\n",
      "522:\tlearn: 0.9701564\ttotal: 1m 47s\tremaining: 1m 38s\n",
      "523:\tlearn: 0.9683916\ttotal: 1m 48s\tremaining: 1m 38s\n",
      "524:\tlearn: 0.9654848\ttotal: 1m 48s\tremaining: 1m 37s\n",
      "525:\tlearn: 0.9627057\ttotal: 1m 48s\tremaining: 1m 37s\n",
      "526:\tlearn: 0.9611240\ttotal: 1m 48s\tremaining: 1m 37s\n",
      "527:\tlearn: 0.9587903\ttotal: 1m 48s\tremaining: 1m 37s\n",
      "528:\tlearn: 0.9569549\ttotal: 1m 49s\tremaining: 1m 37s\n",
      "529:\tlearn: 0.9554551\ttotal: 1m 49s\tremaining: 1m 37s\n",
      "530:\tlearn: 0.9548461\ttotal: 1m 49s\tremaining: 1m 36s\n",
      "531:\tlearn: 0.9530264\ttotal: 1m 49s\tremaining: 1m 36s\n",
      "532:\tlearn: 0.9505224\ttotal: 1m 50s\tremaining: 1m 36s\n",
      "533:\tlearn: 0.9480176\ttotal: 1m 50s\tremaining: 1m 36s\n",
      "534:\tlearn: 0.9456033\ttotal: 1m 50s\tremaining: 1m 35s\n",
      "535:\tlearn: 0.9426250\ttotal: 1m 50s\tremaining: 1m 35s\n",
      "536:\tlearn: 0.9407276\ttotal: 1m 50s\tremaining: 1m 35s\n",
      "537:\tlearn: 0.9389797\ttotal: 1m 51s\tremaining: 1m 35s\n",
      "538:\tlearn: 0.9359164\ttotal: 1m 51s\tremaining: 1m 35s\n",
      "539:\tlearn: 0.9343657\ttotal: 1m 51s\tremaining: 1m 34s\n",
      "540:\tlearn: 0.9336525\ttotal: 1m 51s\tremaining: 1m 34s\n",
      "541:\tlearn: 0.9310688\ttotal: 1m 51s\tremaining: 1m 34s\n",
      "542:\tlearn: 0.9299320\ttotal: 1m 52s\tremaining: 1m 34s\n",
      "543:\tlearn: 0.9287071\ttotal: 1m 52s\tremaining: 1m 34s\n",
      "544:\tlearn: 0.9258984\ttotal: 1m 52s\tremaining: 1m 33s\n",
      "545:\tlearn: 0.9242687\ttotal: 1m 52s\tremaining: 1m 33s\n",
      "546:\tlearn: 0.9227387\ttotal: 1m 52s\tremaining: 1m 33s\n",
      "547:\tlearn: 0.9208690\ttotal: 1m 53s\tremaining: 1m 33s\n",
      "548:\tlearn: 0.9182063\ttotal: 1m 53s\tremaining: 1m 33s\n",
      "549:\tlearn: 0.9166113\ttotal: 1m 53s\tremaining: 1m 32s\n",
      "550:\tlearn: 0.9139392\ttotal: 1m 53s\tremaining: 1m 32s\n",
      "551:\tlearn: 0.9120141\ttotal: 1m 53s\tremaining: 1m 32s\n",
      "552:\tlearn: 0.9105343\ttotal: 1m 54s\tremaining: 1m 32s\n",
      "553:\tlearn: 0.9076843\ttotal: 1m 54s\tremaining: 1m 31s\n",
      "554:\tlearn: 0.9052296\ttotal: 1m 54s\tremaining: 1m 31s\n",
      "555:\tlearn: 0.9036530\ttotal: 1m 54s\tremaining: 1m 31s\n",
      "556:\tlearn: 0.9023425\ttotal: 1m 54s\tremaining: 1m 31s\n",
      "557:\tlearn: 0.8990370\ttotal: 1m 55s\tremaining: 1m 31s\n",
      "558:\tlearn: 0.8977034\ttotal: 1m 55s\tremaining: 1m 30s\n",
      "559:\tlearn: 0.8954921\ttotal: 1m 55s\tremaining: 1m 30s\n",
      "560:\tlearn: 0.8943730\ttotal: 1m 55s\tremaining: 1m 30s\n",
      "561:\tlearn: 0.8934727\ttotal: 1m 55s\tremaining: 1m 30s\n",
      "562:\tlearn: 0.8899944\ttotal: 1m 55s\tremaining: 1m 30s\n",
      "563:\tlearn: 0.8878353\ttotal: 1m 56s\tremaining: 1m 29s\n",
      "564:\tlearn: 0.8867487\ttotal: 1m 56s\tremaining: 1m 29s\n",
      "565:\tlearn: 0.8847958\ttotal: 1m 56s\tremaining: 1m 29s\n",
      "566:\tlearn: 0.8834855\ttotal: 1m 56s\tremaining: 1m 29s\n",
      "567:\tlearn: 0.8811532\ttotal: 1m 57s\tremaining: 1m 28s\n",
      "568:\tlearn: 0.8793515\ttotal: 1m 57s\tremaining: 1m 28s\n",
      "569:\tlearn: 0.8773068\ttotal: 1m 57s\tremaining: 1m 28s\n",
      "570:\tlearn: 0.8746707\ttotal: 1m 57s\tremaining: 1m 28s\n",
      "571:\tlearn: 0.8729762\ttotal: 1m 57s\tremaining: 1m 28s\n",
      "572:\tlearn: 0.8704488\ttotal: 1m 58s\tremaining: 1m 27s\n",
      "573:\tlearn: 0.8680998\ttotal: 1m 58s\tremaining: 1m 27s\n",
      "574:\tlearn: 0.8667557\ttotal: 1m 58s\tremaining: 1m 27s\n",
      "575:\tlearn: 0.8644764\ttotal: 1m 58s\tremaining: 1m 27s\n",
      "576:\tlearn: 0.8631625\ttotal: 1m 58s\tremaining: 1m 27s\n",
      "577:\tlearn: 0.8615573\ttotal: 1m 59s\tremaining: 1m 26s\n",
      "578:\tlearn: 0.8598405\ttotal: 1m 59s\tremaining: 1m 26s\n",
      "579:\tlearn: 0.8579304\ttotal: 1m 59s\tremaining: 1m 26s\n",
      "580:\tlearn: 0.8563243\ttotal: 1m 59s\tremaining: 1m 26s\n",
      "581:\tlearn: 0.8546258\ttotal: 1m 59s\tremaining: 1m 26s\n",
      "582:\tlearn: 0.8530489\ttotal: 2m\tremaining: 1m 25s\n",
      "583:\tlearn: 0.8509749\ttotal: 2m\tremaining: 1m 25s\n",
      "584:\tlearn: 0.8493873\ttotal: 2m\tremaining: 1m 25s\n",
      "585:\tlearn: 0.8466653\ttotal: 2m\tremaining: 1m 25s\n",
      "586:\tlearn: 0.8444874\ttotal: 2m\tremaining: 1m 25s\n",
      "587:\tlearn: 0.8435065\ttotal: 2m 1s\tremaining: 1m 24s\n",
      "588:\tlearn: 0.8411770\ttotal: 2m 1s\tremaining: 1m 24s\n",
      "589:\tlearn: 0.8393104\ttotal: 2m 1s\tremaining: 1m 24s\n",
      "590:\tlearn: 0.8381304\ttotal: 2m 1s\tremaining: 1m 24s\n",
      "591:\tlearn: 0.8363953\ttotal: 2m 1s\tremaining: 1m 23s\n",
      "592:\tlearn: 0.8355376\ttotal: 2m 2s\tremaining: 1m 23s\n",
      "593:\tlearn: 0.8336778\ttotal: 2m 2s\tremaining: 1m 23s\n",
      "594:\tlearn: 0.8322480\ttotal: 2m 2s\tremaining: 1m 23s\n",
      "595:\tlearn: 0.8303580\ttotal: 2m 2s\tremaining: 1m 23s\n",
      "596:\tlearn: 0.8280224\ttotal: 2m 2s\tremaining: 1m 22s\n",
      "597:\tlearn: 0.8262697\ttotal: 2m 3s\tremaining: 1m 22s\n",
      "598:\tlearn: 0.8240012\ttotal: 2m 3s\tremaining: 1m 22s\n",
      "599:\tlearn: 0.8216512\ttotal: 2m 3s\tremaining: 1m 22s\n",
      "600:\tlearn: 0.8207620\ttotal: 2m 3s\tremaining: 1m 22s\n",
      "601:\tlearn: 0.8197877\ttotal: 2m 3s\tremaining: 1m 21s\n",
      "602:\tlearn: 0.8184716\ttotal: 2m 4s\tremaining: 1m 21s\n",
      "603:\tlearn: 0.8169727\ttotal: 2m 4s\tremaining: 1m 21s\n",
      "604:\tlearn: 0.8150688\ttotal: 2m 4s\tremaining: 1m 21s\n",
      "605:\tlearn: 0.8135046\ttotal: 2m 4s\tremaining: 1m 21s\n",
      "606:\tlearn: 0.8115043\ttotal: 2m 4s\tremaining: 1m 20s\n",
      "607:\tlearn: 0.8097765\ttotal: 2m 5s\tremaining: 1m 20s\n",
      "608:\tlearn: 0.8081140\ttotal: 2m 5s\tremaining: 1m 20s\n",
      "609:\tlearn: 0.8069233\ttotal: 2m 5s\tremaining: 1m 20s\n",
      "610:\tlearn: 0.8054900\ttotal: 2m 5s\tremaining: 1m 20s\n",
      "611:\tlearn: 0.8048788\ttotal: 2m 5s\tremaining: 1m 19s\n",
      "612:\tlearn: 0.8033709\ttotal: 2m 6s\tremaining: 1m 19s\n",
      "613:\tlearn: 0.8017882\ttotal: 2m 6s\tremaining: 1m 19s\n",
      "614:\tlearn: 0.8011236\ttotal: 2m 6s\tremaining: 1m 19s\n",
      "615:\tlearn: 0.7997857\ttotal: 2m 6s\tremaining: 1m 18s\n",
      "616:\tlearn: 0.7989314\ttotal: 2m 6s\tremaining: 1m 18s\n",
      "617:\tlearn: 0.7967544\ttotal: 2m 7s\tremaining: 1m 18s\n",
      "618:\tlearn: 0.7953701\ttotal: 2m 7s\tremaining: 1m 18s\n",
      "619:\tlearn: 0.7940396\ttotal: 2m 7s\tremaining: 1m 18s\n",
      "620:\tlearn: 0.7922214\ttotal: 2m 7s\tremaining: 1m 17s\n",
      "621:\tlearn: 0.7909681\ttotal: 2m 7s\tremaining: 1m 17s\n",
      "622:\tlearn: 0.7881412\ttotal: 2m 8s\tremaining: 1m 17s\n",
      "623:\tlearn: 0.7868027\ttotal: 2m 8s\tremaining: 1m 17s\n",
      "624:\tlearn: 0.7856869\ttotal: 2m 8s\tremaining: 1m 17s\n",
      "625:\tlearn: 0.7841830\ttotal: 2m 8s\tremaining: 1m 16s\n",
      "626:\tlearn: 0.7828040\ttotal: 2m 8s\tremaining: 1m 16s\n",
      "627:\tlearn: 0.7805366\ttotal: 2m 9s\tremaining: 1m 16s\n",
      "628:\tlearn: 0.7783940\ttotal: 2m 9s\tremaining: 1m 16s\n",
      "629:\tlearn: 0.7764463\ttotal: 2m 9s\tremaining: 1m 16s\n",
      "630:\tlearn: 0.7754259\ttotal: 2m 9s\tremaining: 1m 15s\n",
      "631:\tlearn: 0.7739171\ttotal: 2m 9s\tremaining: 1m 15s\n",
      "632:\tlearn: 0.7723809\ttotal: 2m 10s\tremaining: 1m 15s\n",
      "633:\tlearn: 0.7711663\ttotal: 2m 10s\tremaining: 1m 15s\n",
      "634:\tlearn: 0.7703528\ttotal: 2m 10s\tremaining: 1m 15s\n",
      "635:\tlearn: 0.7691199\ttotal: 2m 10s\tremaining: 1m 14s\n",
      "636:\tlearn: 0.7680375\ttotal: 2m 10s\tremaining: 1m 14s\n",
      "637:\tlearn: 0.7665889\ttotal: 2m 11s\tremaining: 1m 14s\n",
      "638:\tlearn: 0.7656854\ttotal: 2m 11s\tremaining: 1m 14s\n",
      "639:\tlearn: 0.7634518\ttotal: 2m 11s\tremaining: 1m 13s\n",
      "640:\tlearn: 0.7616703\ttotal: 2m 11s\tremaining: 1m 13s\n",
      "641:\tlearn: 0.7602046\ttotal: 2m 11s\tremaining: 1m 13s\n",
      "642:\tlearn: 0.7590197\ttotal: 2m 12s\tremaining: 1m 13s\n",
      "643:\tlearn: 0.7565396\ttotal: 2m 12s\tremaining: 1m 13s\n",
      "644:\tlearn: 0.7555713\ttotal: 2m 12s\tremaining: 1m 12s\n",
      "645:\tlearn: 0.7549297\ttotal: 2m 12s\tremaining: 1m 12s\n",
      "646:\tlearn: 0.7536080\ttotal: 2m 12s\tremaining: 1m 12s\n",
      "647:\tlearn: 0.7508145\ttotal: 2m 12s\tremaining: 1m 12s\n",
      "648:\tlearn: 0.7494473\ttotal: 2m 13s\tremaining: 1m 12s\n",
      "649:\tlearn: 0.7485743\ttotal: 2m 13s\tremaining: 1m 11s\n",
      "650:\tlearn: 0.7466164\ttotal: 2m 13s\tremaining: 1m 11s\n",
      "651:\tlearn: 0.7448814\ttotal: 2m 13s\tremaining: 1m 11s\n",
      "652:\tlearn: 0.7436611\ttotal: 2m 13s\tremaining: 1m 11s\n",
      "653:\tlearn: 0.7413235\ttotal: 2m 14s\tremaining: 1m 10s\n",
      "654:\tlearn: 0.7396385\ttotal: 2m 14s\tremaining: 1m 10s\n",
      "655:\tlearn: 0.7386468\ttotal: 2m 14s\tremaining: 1m 10s\n",
      "656:\tlearn: 0.7365275\ttotal: 2m 14s\tremaining: 1m 10s\n",
      "657:\tlearn: 0.7348831\ttotal: 2m 14s\tremaining: 1m 10s\n",
      "658:\tlearn: 0.7333923\ttotal: 2m 15s\tremaining: 1m 9s\n",
      "659:\tlearn: 0.7315696\ttotal: 2m 15s\tremaining: 1m 9s\n",
      "660:\tlearn: 0.7304179\ttotal: 2m 15s\tremaining: 1m 9s\n",
      "661:\tlearn: 0.7286165\ttotal: 2m 15s\tremaining: 1m 9s\n",
      "662:\tlearn: 0.7275220\ttotal: 2m 15s\tremaining: 1m 9s\n",
      "663:\tlearn: 0.7264885\ttotal: 2m 16s\tremaining: 1m 8s\n",
      "664:\tlearn: 0.7249046\ttotal: 2m 16s\tremaining: 1m 8s\n",
      "665:\tlearn: 0.7239246\ttotal: 2m 16s\tremaining: 1m 8s\n",
      "666:\tlearn: 0.7234010\ttotal: 2m 16s\tremaining: 1m 8s\n",
      "667:\tlearn: 0.7211053\ttotal: 2m 16s\tremaining: 1m 7s\n",
      "668:\tlearn: 0.7202248\ttotal: 2m 16s\tremaining: 1m 7s\n",
      "669:\tlearn: 0.7186593\ttotal: 2m 17s\tremaining: 1m 7s\n",
      "670:\tlearn: 0.7179670\ttotal: 2m 17s\tremaining: 1m 7s\n",
      "671:\tlearn: 0.7164373\ttotal: 2m 17s\tremaining: 1m 7s\n",
      "672:\tlearn: 0.7144544\ttotal: 2m 17s\tremaining: 1m 6s\n",
      "673:\tlearn: 0.7140479\ttotal: 2m 17s\tremaining: 1m 6s\n",
      "674:\tlearn: 0.7121984\ttotal: 2m 18s\tremaining: 1m 6s\n",
      "675:\tlearn: 0.7110844\ttotal: 2m 18s\tremaining: 1m 6s\n",
      "676:\tlearn: 0.7095908\ttotal: 2m 18s\tremaining: 1m 6s\n",
      "677:\tlearn: 0.7083806\ttotal: 2m 18s\tremaining: 1m 5s\n",
      "678:\tlearn: 0.7068886\ttotal: 2m 18s\tremaining: 1m 5s\n",
      "679:\tlearn: 0.7060561\ttotal: 2m 19s\tremaining: 1m 5s\n",
      "680:\tlearn: 0.7042560\ttotal: 2m 19s\tremaining: 1m 5s\n",
      "681:\tlearn: 0.7029756\ttotal: 2m 19s\tremaining: 1m 5s\n",
      "682:\tlearn: 0.7008706\ttotal: 2m 19s\tremaining: 1m 4s\n",
      "683:\tlearn: 0.7003492\ttotal: 2m 20s\tremaining: 1m 4s\n",
      "684:\tlearn: 0.6994547\ttotal: 2m 20s\tremaining: 1m 4s\n",
      "685:\tlearn: 0.6984635\ttotal: 2m 20s\tremaining: 1m 4s\n",
      "686:\tlearn: 0.6970596\ttotal: 2m 20s\tremaining: 1m 4s\n",
      "687:\tlearn: 0.6962575\ttotal: 2m 20s\tremaining: 1m 3s\n",
      "688:\tlearn: 0.6956953\ttotal: 2m 21s\tremaining: 1m 3s\n",
      "689:\tlearn: 0.6936586\ttotal: 2m 21s\tremaining: 1m 3s\n",
      "690:\tlearn: 0.6916530\ttotal: 2m 21s\tremaining: 1m 3s\n",
      "691:\tlearn: 0.6908367\ttotal: 2m 21s\tremaining: 1m 3s\n",
      "692:\tlearn: 0.6900437\ttotal: 2m 21s\tremaining: 1m 2s\n",
      "693:\tlearn: 0.6882265\ttotal: 2m 21s\tremaining: 1m 2s\n",
      "694:\tlearn: 0.6872308\ttotal: 2m 22s\tremaining: 1m 2s\n",
      "695:\tlearn: 0.6854891\ttotal: 2m 22s\tremaining: 1m 2s\n",
      "696:\tlearn: 0.6838685\ttotal: 2m 22s\tremaining: 1m 1s\n",
      "697:\tlearn: 0.6824666\ttotal: 2m 22s\tremaining: 1m 1s\n",
      "698:\tlearn: 0.6810438\ttotal: 2m 22s\tremaining: 1m 1s\n",
      "699:\tlearn: 0.6790364\ttotal: 2m 23s\tremaining: 1m 1s\n",
      "700:\tlearn: 0.6776146\ttotal: 2m 23s\tremaining: 1m 1s\n",
      "701:\tlearn: 0.6758434\ttotal: 2m 23s\tremaining: 1m\n",
      "702:\tlearn: 0.6746974\ttotal: 2m 23s\tremaining: 1m\n",
      "703:\tlearn: 0.6730572\ttotal: 2m 23s\tremaining: 1m\n",
      "704:\tlearn: 0.6712160\ttotal: 2m 24s\tremaining: 1m\n",
      "705:\tlearn: 0.6698145\ttotal: 2m 24s\tremaining: 1m\n",
      "706:\tlearn: 0.6670439\ttotal: 2m 24s\tremaining: 59.9s\n",
      "707:\tlearn: 0.6649046\ttotal: 2m 24s\tremaining: 59.7s\n",
      "708:\tlearn: 0.6633911\ttotal: 2m 24s\tremaining: 59.5s\n",
      "709:\tlearn: 0.6618300\ttotal: 2m 25s\tremaining: 59.3s\n",
      "710:\tlearn: 0.6606686\ttotal: 2m 25s\tremaining: 59.1s\n",
      "711:\tlearn: 0.6587096\ttotal: 2m 25s\tremaining: 58.8s\n",
      "712:\tlearn: 0.6562970\ttotal: 2m 25s\tremaining: 58.6s\n",
      "713:\tlearn: 0.6555621\ttotal: 2m 25s\tremaining: 58.4s\n",
      "714:\tlearn: 0.6543178\ttotal: 2m 26s\tremaining: 58.2s\n",
      "715:\tlearn: 0.6530384\ttotal: 2m 26s\tremaining: 58s\n",
      "716:\tlearn: 0.6519014\ttotal: 2m 26s\tremaining: 57.8s\n",
      "717:\tlearn: 0.6506422\ttotal: 2m 26s\tremaining: 57.6s\n",
      "718:\tlearn: 0.6497552\ttotal: 2m 26s\tremaining: 57.4s\n",
      "719:\tlearn: 0.6486484\ttotal: 2m 27s\tremaining: 57.2s\n",
      "720:\tlearn: 0.6470552\ttotal: 2m 27s\tremaining: 57s\n",
      "721:\tlearn: 0.6462170\ttotal: 2m 27s\tremaining: 56.8s\n",
      "722:\tlearn: 0.6453335\ttotal: 2m 27s\tremaining: 56.5s\n",
      "723:\tlearn: 0.6441698\ttotal: 2m 27s\tremaining: 56.3s\n",
      "724:\tlearn: 0.6427132\ttotal: 2m 27s\tremaining: 56.1s\n",
      "725:\tlearn: 0.6413480\ttotal: 2m 28s\tremaining: 55.9s\n",
      "726:\tlearn: 0.6399740\ttotal: 2m 28s\tremaining: 55.7s\n",
      "727:\tlearn: 0.6387529\ttotal: 2m 28s\tremaining: 55.5s\n",
      "728:\tlearn: 0.6383265\ttotal: 2m 28s\tremaining: 55.3s\n",
      "729:\tlearn: 0.6371718\ttotal: 2m 28s\tremaining: 55.1s\n",
      "730:\tlearn: 0.6362286\ttotal: 2m 29s\tremaining: 54.9s\n",
      "731:\tlearn: 0.6348925\ttotal: 2m 29s\tremaining: 54.7s\n",
      "732:\tlearn: 0.6336070\ttotal: 2m 29s\tremaining: 54.5s\n",
      "733:\tlearn: 0.6326363\ttotal: 2m 29s\tremaining: 54.2s\n",
      "734:\tlearn: 0.6310003\ttotal: 2m 29s\tremaining: 54s\n",
      "735:\tlearn: 0.6299414\ttotal: 2m 29s\tremaining: 53.8s\n",
      "736:\tlearn: 0.6285592\ttotal: 2m 30s\tremaining: 53.6s\n",
      "737:\tlearn: 0.6276983\ttotal: 2m 30s\tremaining: 53.3s\n",
      "738:\tlearn: 0.6266077\ttotal: 2m 30s\tremaining: 53.1s\n",
      "739:\tlearn: 0.6252854\ttotal: 2m 30s\tremaining: 52.9s\n",
      "740:\tlearn: 0.6241563\ttotal: 2m 30s\tremaining: 52.7s\n",
      "741:\tlearn: 0.6228098\ttotal: 2m 30s\tremaining: 52.5s\n",
      "742:\tlearn: 0.6215413\ttotal: 2m 31s\tremaining: 52.3s\n",
      "743:\tlearn: 0.6206497\ttotal: 2m 31s\tremaining: 52s\n",
      "744:\tlearn: 0.6196148\ttotal: 2m 31s\tremaining: 51.8s\n",
      "745:\tlearn: 0.6183745\ttotal: 2m 31s\tremaining: 51.6s\n",
      "746:\tlearn: 0.6172121\ttotal: 2m 31s\tremaining: 51.4s\n",
      "747:\tlearn: 0.6163305\ttotal: 2m 32s\tremaining: 51.2s\n",
      "748:\tlearn: 0.6147118\ttotal: 2m 32s\tremaining: 51s\n",
      "749:\tlearn: 0.6129740\ttotal: 2m 32s\tremaining: 50.8s\n",
      "750:\tlearn: 0.6115449\ttotal: 2m 32s\tremaining: 50.6s\n",
      "751:\tlearn: 0.6094353\ttotal: 2m 32s\tremaining: 50.4s\n",
      "752:\tlearn: 0.6080708\ttotal: 2m 33s\tremaining: 50.2s\n",
      "753:\tlearn: 0.6060220\ttotal: 2m 33s\tremaining: 50s\n",
      "754:\tlearn: 0.6054793\ttotal: 2m 33s\tremaining: 49.8s\n",
      "755:\tlearn: 0.6037047\ttotal: 2m 33s\tremaining: 49.6s\n",
      "756:\tlearn: 0.6027482\ttotal: 2m 33s\tremaining: 49.3s\n",
      "757:\tlearn: 0.6012555\ttotal: 2m 33s\tremaining: 49.1s\n",
      "758:\tlearn: 0.6001642\ttotal: 2m 34s\tremaining: 48.9s\n",
      "759:\tlearn: 0.5994231\ttotal: 2m 34s\tremaining: 48.7s\n",
      "760:\tlearn: 0.5979006\ttotal: 2m 34s\tremaining: 48.5s\n",
      "761:\tlearn: 0.5970938\ttotal: 2m 34s\tremaining: 48.3s\n",
      "762:\tlearn: 0.5951195\ttotal: 2m 34s\tremaining: 48.1s\n",
      "763:\tlearn: 0.5939408\ttotal: 2m 35s\tremaining: 47.9s\n",
      "764:\tlearn: 0.5926161\ttotal: 2m 35s\tremaining: 47.7s\n",
      "765:\tlearn: 0.5919680\ttotal: 2m 35s\tremaining: 47.5s\n",
      "766:\tlearn: 0.5910379\ttotal: 2m 35s\tremaining: 47.2s\n",
      "767:\tlearn: 0.5901970\ttotal: 2m 35s\tremaining: 47s\n",
      "768:\tlearn: 0.5886925\ttotal: 2m 35s\tremaining: 46.8s\n",
      "769:\tlearn: 0.5872413\ttotal: 2m 36s\tremaining: 46.6s\n",
      "770:\tlearn: 0.5857987\ttotal: 2m 36s\tremaining: 46.4s\n",
      "771:\tlearn: 0.5842198\ttotal: 2m 36s\tremaining: 46.2s\n",
      "772:\tlearn: 0.5831654\ttotal: 2m 36s\tremaining: 46s\n",
      "773:\tlearn: 0.5822499\ttotal: 2m 36s\tremaining: 45.8s\n",
      "774:\tlearn: 0.5812472\ttotal: 2m 37s\tremaining: 45.6s\n",
      "775:\tlearn: 0.5803664\ttotal: 2m 37s\tremaining: 45.4s\n",
      "776:\tlearn: 0.5792966\ttotal: 2m 37s\tremaining: 45.2s\n",
      "777:\tlearn: 0.5785141\ttotal: 2m 37s\tremaining: 45s\n",
      "778:\tlearn: 0.5768742\ttotal: 2m 37s\tremaining: 44.8s\n",
      "779:\tlearn: 0.5759245\ttotal: 2m 38s\tremaining: 44.6s\n",
      "780:\tlearn: 0.5749605\ttotal: 2m 38s\tremaining: 44.4s\n",
      "781:\tlearn: 0.5737139\ttotal: 2m 38s\tremaining: 44.2s\n",
      "782:\tlearn: 0.5722689\ttotal: 2m 38s\tremaining: 44s\n",
      "783:\tlearn: 0.5711880\ttotal: 2m 39s\tremaining: 43.8s\n",
      "784:\tlearn: 0.5701944\ttotal: 2m 39s\tremaining: 43.6s\n",
      "785:\tlearn: 0.5694258\ttotal: 2m 39s\tremaining: 43.4s\n",
      "786:\tlearn: 0.5688161\ttotal: 2m 39s\tremaining: 43.2s\n",
      "787:\tlearn: 0.5673755\ttotal: 2m 39s\tremaining: 43s\n",
      "788:\tlearn: 0.5665314\ttotal: 2m 40s\tremaining: 42.8s\n",
      "789:\tlearn: 0.5659615\ttotal: 2m 40s\tremaining: 42.6s\n",
      "790:\tlearn: 0.5650832\ttotal: 2m 40s\tremaining: 42.4s\n",
      "791:\tlearn: 0.5638147\ttotal: 2m 40s\tremaining: 42.2s\n",
      "792:\tlearn: 0.5629408\ttotal: 2m 41s\tremaining: 42.1s\n",
      "793:\tlearn: 0.5623041\ttotal: 2m 41s\tremaining: 41.9s\n",
      "794:\tlearn: 0.5610255\ttotal: 2m 41s\tremaining: 41.7s\n",
      "795:\tlearn: 0.5595959\ttotal: 2m 41s\tremaining: 41.5s\n",
      "796:\tlearn: 0.5582647\ttotal: 2m 42s\tremaining: 41.3s\n",
      "797:\tlearn: 0.5565920\ttotal: 2m 42s\tremaining: 41.1s\n",
      "798:\tlearn: 0.5557197\ttotal: 2m 42s\tremaining: 40.9s\n",
      "799:\tlearn: 0.5550346\ttotal: 2m 42s\tremaining: 40.7s\n",
      "800:\tlearn: 0.5536839\ttotal: 2m 42s\tremaining: 40.5s\n",
      "801:\tlearn: 0.5526485\ttotal: 2m 43s\tremaining: 40.3s\n",
      "802:\tlearn: 0.5515461\ttotal: 2m 43s\tremaining: 40.1s\n",
      "803:\tlearn: 0.5496510\ttotal: 2m 43s\tremaining: 39.9s\n",
      "804:\tlearn: 0.5491702\ttotal: 2m 43s\tremaining: 39.7s\n",
      "805:\tlearn: 0.5485284\ttotal: 2m 44s\tremaining: 39.5s\n",
      "806:\tlearn: 0.5476399\ttotal: 2m 44s\tremaining: 39.3s\n",
      "807:\tlearn: 0.5459491\ttotal: 2m 44s\tremaining: 39.1s\n",
      "808:\tlearn: 0.5453623\ttotal: 2m 44s\tremaining: 38.9s\n",
      "809:\tlearn: 0.5441358\ttotal: 2m 44s\tremaining: 38.7s\n",
      "810:\tlearn: 0.5431292\ttotal: 2m 45s\tremaining: 38.5s\n",
      "811:\tlearn: 0.5417554\ttotal: 2m 45s\tremaining: 38.3s\n",
      "812:\tlearn: 0.5409412\ttotal: 2m 45s\tremaining: 38.1s\n",
      "813:\tlearn: 0.5405949\ttotal: 2m 45s\tremaining: 37.9s\n",
      "814:\tlearn: 0.5390742\ttotal: 2m 45s\tremaining: 37.7s\n",
      "815:\tlearn: 0.5381563\ttotal: 2m 46s\tremaining: 37.5s\n",
      "816:\tlearn: 0.5370502\ttotal: 2m 46s\tremaining: 37.2s\n",
      "817:\tlearn: 0.5354730\ttotal: 2m 46s\tremaining: 37s\n",
      "818:\tlearn: 0.5347466\ttotal: 2m 46s\tremaining: 36.8s\n",
      "819:\tlearn: 0.5337957\ttotal: 2m 46s\tremaining: 36.6s\n",
      "820:\tlearn: 0.5329743\ttotal: 2m 47s\tremaining: 36.4s\n",
      "821:\tlearn: 0.5319643\ttotal: 2m 47s\tremaining: 36.2s\n",
      "822:\tlearn: 0.5303666\ttotal: 2m 47s\tremaining: 36s\n",
      "823:\tlearn: 0.5294420\ttotal: 2m 47s\tremaining: 35.8s\n",
      "824:\tlearn: 0.5280482\ttotal: 2m 47s\tremaining: 35.6s\n",
      "825:\tlearn: 0.5273692\ttotal: 2m 48s\tremaining: 35.4s\n",
      "826:\tlearn: 0.5268805\ttotal: 2m 48s\tremaining: 35.2s\n",
      "827:\tlearn: 0.5261006\ttotal: 2m 48s\tremaining: 35s\n",
      "828:\tlearn: 0.5250141\ttotal: 2m 48s\tremaining: 34.8s\n",
      "829:\tlearn: 0.5237994\ttotal: 2m 48s\tremaining: 34.6s\n",
      "830:\tlearn: 0.5227763\ttotal: 2m 49s\tremaining: 34.4s\n",
      "831:\tlearn: 0.5222210\ttotal: 2m 49s\tremaining: 34.2s\n",
      "832:\tlearn: 0.5211146\ttotal: 2m 49s\tremaining: 34s\n",
      "833:\tlearn: 0.5195533\ttotal: 2m 49s\tremaining: 33.8s\n",
      "834:\tlearn: 0.5193250\ttotal: 2m 49s\tremaining: 33.6s\n",
      "835:\tlearn: 0.5181709\ttotal: 2m 50s\tremaining: 33.4s\n",
      "836:\tlearn: 0.5173727\ttotal: 2m 50s\tremaining: 33.2s\n",
      "837:\tlearn: 0.5166339\ttotal: 2m 50s\tremaining: 33s\n",
      "838:\tlearn: 0.5159327\ttotal: 2m 50s\tremaining: 32.8s\n",
      "839:\tlearn: 0.5147924\ttotal: 2m 50s\tremaining: 32.6s\n",
      "840:\tlearn: 0.5138645\ttotal: 2m 51s\tremaining: 32.4s\n",
      "841:\tlearn: 0.5129254\ttotal: 2m 51s\tremaining: 32.1s\n",
      "842:\tlearn: 0.5121148\ttotal: 2m 51s\tremaining: 31.9s\n",
      "843:\tlearn: 0.5113299\ttotal: 2m 51s\tremaining: 31.7s\n",
      "844:\tlearn: 0.5108007\ttotal: 2m 51s\tremaining: 31.5s\n",
      "845:\tlearn: 0.5101455\ttotal: 2m 52s\tremaining: 31.3s\n",
      "846:\tlearn: 0.5090732\ttotal: 2m 52s\tremaining: 31.1s\n",
      "847:\tlearn: 0.5080491\ttotal: 2m 52s\tremaining: 30.9s\n",
      "848:\tlearn: 0.5066251\ttotal: 2m 52s\tremaining: 30.7s\n",
      "849:\tlearn: 0.5057251\ttotal: 2m 52s\tremaining: 30.5s\n",
      "850:\tlearn: 0.5051423\ttotal: 2m 53s\tremaining: 30.3s\n",
      "851:\tlearn: 0.5044519\ttotal: 2m 53s\tremaining: 30.1s\n",
      "852:\tlearn: 0.5032971\ttotal: 2m 53s\tremaining: 29.9s\n",
      "853:\tlearn: 0.5029218\ttotal: 2m 53s\tremaining: 29.7s\n",
      "854:\tlearn: 0.5018486\ttotal: 2m 53s\tremaining: 29.5s\n",
      "855:\tlearn: 0.5009021\ttotal: 2m 53s\tremaining: 29.3s\n",
      "856:\tlearn: 0.5000415\ttotal: 2m 54s\tremaining: 29.1s\n",
      "857:\tlearn: 0.4992481\ttotal: 2m 54s\tremaining: 28.8s\n",
      "858:\tlearn: 0.4979530\ttotal: 2m 54s\tremaining: 28.6s\n",
      "859:\tlearn: 0.4969783\ttotal: 2m 54s\tremaining: 28.4s\n",
      "860:\tlearn: 0.4959080\ttotal: 2m 54s\tremaining: 28.2s\n",
      "861:\tlearn: 0.4951906\ttotal: 2m 55s\tremaining: 28s\n",
      "862:\tlearn: 0.4940779\ttotal: 2m 55s\tremaining: 27.8s\n",
      "863:\tlearn: 0.4931144\ttotal: 2m 55s\tremaining: 27.6s\n",
      "864:\tlearn: 0.4924242\ttotal: 2m 55s\tremaining: 27.4s\n",
      "865:\tlearn: 0.4917544\ttotal: 2m 55s\tremaining: 27.2s\n",
      "866:\tlearn: 0.4911077\ttotal: 2m 55s\tremaining: 27s\n",
      "867:\tlearn: 0.4903021\ttotal: 2m 56s\tremaining: 26.8s\n",
      "868:\tlearn: 0.4890341\ttotal: 2m 56s\tremaining: 26.6s\n",
      "869:\tlearn: 0.4880252\ttotal: 2m 56s\tremaining: 26.4s\n",
      "870:\tlearn: 0.4869463\ttotal: 2m 56s\tremaining: 26.2s\n",
      "871:\tlearn: 0.4860552\ttotal: 2m 56s\tremaining: 26s\n",
      "872:\tlearn: 0.4852618\ttotal: 2m 57s\tremaining: 25.8s\n",
      "873:\tlearn: 0.4842852\ttotal: 2m 57s\tremaining: 25.6s\n",
      "874:\tlearn: 0.4833775\ttotal: 2m 57s\tremaining: 25.4s\n",
      "875:\tlearn: 0.4821121\ttotal: 2m 57s\tremaining: 25.2s\n",
      "876:\tlearn: 0.4810140\ttotal: 2m 57s\tremaining: 24.9s\n",
      "877:\tlearn: 0.4804182\ttotal: 2m 58s\tremaining: 24.7s\n",
      "878:\tlearn: 0.4798368\ttotal: 2m 58s\tremaining: 24.5s\n",
      "879:\tlearn: 0.4787987\ttotal: 2m 58s\tremaining: 24.3s\n",
      "880:\tlearn: 0.4779760\ttotal: 2m 58s\tremaining: 24.1s\n",
      "881:\tlearn: 0.4774913\ttotal: 2m 58s\tremaining: 23.9s\n",
      "882:\tlearn: 0.4769029\ttotal: 2m 58s\tremaining: 23.7s\n",
      "883:\tlearn: 0.4757866\ttotal: 2m 59s\tremaining: 23.5s\n",
      "884:\tlearn: 0.4749184\ttotal: 2m 59s\tremaining: 23.3s\n",
      "885:\tlearn: 0.4742041\ttotal: 2m 59s\tremaining: 23.1s\n",
      "886:\tlearn: 0.4735289\ttotal: 2m 59s\tremaining: 22.9s\n",
      "887:\tlearn: 0.4725635\ttotal: 2m 59s\tremaining: 22.7s\n",
      "888:\tlearn: 0.4720079\ttotal: 3m\tremaining: 22.5s\n",
      "889:\tlearn: 0.4711834\ttotal: 3m\tremaining: 22.3s\n",
      "890:\tlearn: 0.4703862\ttotal: 3m\tremaining: 22.1s\n",
      "891:\tlearn: 0.4696038\ttotal: 3m\tremaining: 21.9s\n",
      "892:\tlearn: 0.4688663\ttotal: 3m\tremaining: 21.7s\n",
      "893:\tlearn: 0.4678427\ttotal: 3m 1s\tremaining: 21.5s\n",
      "894:\tlearn: 0.4670408\ttotal: 3m 1s\tremaining: 21.3s\n",
      "895:\tlearn: 0.4666762\ttotal: 3m 1s\tremaining: 21.1s\n",
      "896:\tlearn: 0.4659698\ttotal: 3m 1s\tremaining: 20.8s\n",
      "897:\tlearn: 0.4654622\ttotal: 3m 1s\tremaining: 20.6s\n",
      "898:\tlearn: 0.4645210\ttotal: 3m 1s\tremaining: 20.4s\n",
      "899:\tlearn: 0.4636559\ttotal: 3m 2s\tremaining: 20.2s\n",
      "900:\tlearn: 0.4631846\ttotal: 3m 2s\tremaining: 20s\n",
      "901:\tlearn: 0.4626253\ttotal: 3m 2s\tremaining: 19.8s\n",
      "902:\tlearn: 0.4614955\ttotal: 3m 2s\tremaining: 19.6s\n",
      "903:\tlearn: 0.4607073\ttotal: 3m 2s\tremaining: 19.4s\n",
      "904:\tlearn: 0.4595882\ttotal: 3m 2s\tremaining: 19.2s\n",
      "905:\tlearn: 0.4586921\ttotal: 3m 3s\tremaining: 19s\n",
      "906:\tlearn: 0.4580810\ttotal: 3m 3s\tremaining: 18.8s\n",
      "907:\tlearn: 0.4572368\ttotal: 3m 3s\tremaining: 18.6s\n",
      "908:\tlearn: 0.4559723\ttotal: 3m 3s\tremaining: 18.4s\n",
      "909:\tlearn: 0.4553099\ttotal: 3m 4s\tremaining: 18.2s\n",
      "910:\tlearn: 0.4545743\ttotal: 3m 4s\tremaining: 18s\n",
      "911:\tlearn: 0.4542887\ttotal: 3m 4s\tremaining: 17.8s\n",
      "912:\tlearn: 0.4532180\ttotal: 3m 4s\tremaining: 17.6s\n",
      "913:\tlearn: 0.4520353\ttotal: 3m 4s\tremaining: 17.4s\n",
      "914:\tlearn: 0.4515862\ttotal: 3m 4s\tremaining: 17.2s\n",
      "915:\tlearn: 0.4510390\ttotal: 3m 5s\tremaining: 17s\n",
      "916:\tlearn: 0.4502860\ttotal: 3m 5s\tremaining: 16.8s\n",
      "917:\tlearn: 0.4492656\ttotal: 3m 5s\tremaining: 16.6s\n",
      "918:\tlearn: 0.4487623\ttotal: 3m 5s\tremaining: 16.4s\n",
      "919:\tlearn: 0.4482371\ttotal: 3m 5s\tremaining: 16.2s\n",
      "920:\tlearn: 0.4476169\ttotal: 3m 6s\tremaining: 16s\n",
      "921:\tlearn: 0.4468215\ttotal: 3m 6s\tremaining: 15.8s\n",
      "922:\tlearn: 0.4464249\ttotal: 3m 6s\tremaining: 15.5s\n",
      "923:\tlearn: 0.4456493\ttotal: 3m 6s\tremaining: 15.3s\n",
      "924:\tlearn: 0.4446428\ttotal: 3m 6s\tremaining: 15.1s\n",
      "925:\tlearn: 0.4439216\ttotal: 3m 6s\tremaining: 14.9s\n",
      "926:\tlearn: 0.4428302\ttotal: 3m 7s\tremaining: 14.7s\n",
      "927:\tlearn: 0.4420310\ttotal: 3m 7s\tremaining: 14.5s\n",
      "928:\tlearn: 0.4412868\ttotal: 3m 7s\tremaining: 14.3s\n",
      "929:\tlearn: 0.4405519\ttotal: 3m 7s\tremaining: 14.1s\n",
      "930:\tlearn: 0.4395700\ttotal: 3m 7s\tremaining: 13.9s\n",
      "931:\tlearn: 0.4386609\ttotal: 3m 8s\tremaining: 13.7s\n",
      "932:\tlearn: 0.4378874\ttotal: 3m 8s\tremaining: 13.5s\n",
      "933:\tlearn: 0.4372039\ttotal: 3m 8s\tremaining: 13.3s\n",
      "934:\tlearn: 0.4366574\ttotal: 3m 8s\tremaining: 13.1s\n",
      "935:\tlearn: 0.4360933\ttotal: 3m 8s\tremaining: 12.9s\n",
      "936:\tlearn: 0.4352230\ttotal: 3m 8s\tremaining: 12.7s\n",
      "937:\tlearn: 0.4342158\ttotal: 3m 9s\tremaining: 12.5s\n",
      "938:\tlearn: 0.4334651\ttotal: 3m 9s\tremaining: 12.3s\n",
      "939:\tlearn: 0.4322800\ttotal: 3m 9s\tremaining: 12.1s\n",
      "940:\tlearn: 0.4313563\ttotal: 3m 9s\tremaining: 11.9s\n",
      "941:\tlearn: 0.4312296\ttotal: 3m 9s\tremaining: 11.7s\n",
      "942:\tlearn: 0.4298877\ttotal: 3m 10s\tremaining: 11.5s\n",
      "943:\tlearn: 0.4288183\ttotal: 3m 10s\tremaining: 11.3s\n",
      "944:\tlearn: 0.4276401\ttotal: 3m 10s\tremaining: 11.1s\n",
      "945:\tlearn: 0.4271667\ttotal: 3m 10s\tremaining: 10.9s\n",
      "946:\tlearn: 0.4264015\ttotal: 3m 10s\tremaining: 10.7s\n",
      "947:\tlearn: 0.4258142\ttotal: 3m 11s\tremaining: 10.5s\n",
      "948:\tlearn: 0.4249960\ttotal: 3m 11s\tremaining: 10.3s\n",
      "949:\tlearn: 0.4245079\ttotal: 3m 11s\tremaining: 10.1s\n",
      "950:\tlearn: 0.4239872\ttotal: 3m 11s\tremaining: 9.87s\n",
      "951:\tlearn: 0.4232944\ttotal: 3m 11s\tremaining: 9.67s\n",
      "952:\tlearn: 0.4226306\ttotal: 3m 12s\tremaining: 9.47s\n",
      "953:\tlearn: 0.4218393\ttotal: 3m 12s\tremaining: 9.27s\n",
      "954:\tlearn: 0.4210894\ttotal: 3m 12s\tremaining: 9.06s\n",
      "955:\tlearn: 0.4206165\ttotal: 3m 12s\tremaining: 8.86s\n",
      "956:\tlearn: 0.4199206\ttotal: 3m 12s\tremaining: 8.66s\n",
      "957:\tlearn: 0.4195372\ttotal: 3m 12s\tremaining: 8.46s\n",
      "958:\tlearn: 0.4187875\ttotal: 3m 13s\tremaining: 8.26s\n",
      "959:\tlearn: 0.4177011\ttotal: 3m 13s\tremaining: 8.05s\n",
      "960:\tlearn: 0.4171597\ttotal: 3m 13s\tremaining: 7.85s\n",
      "961:\tlearn: 0.4162054\ttotal: 3m 13s\tremaining: 7.65s\n",
      "962:\tlearn: 0.4153123\ttotal: 3m 13s\tremaining: 7.45s\n",
      "963:\tlearn: 0.4145605\ttotal: 3m 14s\tremaining: 7.25s\n",
      "964:\tlearn: 0.4138415\ttotal: 3m 14s\tremaining: 7.05s\n",
      "965:\tlearn: 0.4130669\ttotal: 3m 14s\tremaining: 6.84s\n",
      "966:\tlearn: 0.4126021\ttotal: 3m 14s\tremaining: 6.64s\n",
      "967:\tlearn: 0.4122477\ttotal: 3m 14s\tremaining: 6.44s\n",
      "968:\tlearn: 0.4114053\ttotal: 3m 15s\tremaining: 6.24s\n",
      "969:\tlearn: 0.4107271\ttotal: 3m 15s\tremaining: 6.04s\n",
      "970:\tlearn: 0.4099987\ttotal: 3m 15s\tremaining: 5.83s\n",
      "971:\tlearn: 0.4090699\ttotal: 3m 15s\tremaining: 5.63s\n",
      "972:\tlearn: 0.4088035\ttotal: 3m 15s\tremaining: 5.43s\n",
      "973:\tlearn: 0.4075969\ttotal: 3m 15s\tremaining: 5.23s\n",
      "974:\tlearn: 0.4069622\ttotal: 3m 16s\tremaining: 5.03s\n",
      "975:\tlearn: 0.4060015\ttotal: 3m 16s\tremaining: 4.83s\n",
      "976:\tlearn: 0.4049037\ttotal: 3m 16s\tremaining: 4.63s\n",
      "977:\tlearn: 0.4040694\ttotal: 3m 16s\tremaining: 4.42s\n",
      "978:\tlearn: 0.4036707\ttotal: 3m 16s\tremaining: 4.22s\n",
      "979:\tlearn: 0.4032671\ttotal: 3m 17s\tremaining: 4.02s\n",
      "980:\tlearn: 0.4023114\ttotal: 3m 17s\tremaining: 3.82s\n",
      "981:\tlearn: 0.4013451\ttotal: 3m 17s\tremaining: 3.62s\n",
      "982:\tlearn: 0.4011345\ttotal: 3m 17s\tremaining: 3.42s\n",
      "983:\tlearn: 0.3998274\ttotal: 3m 17s\tremaining: 3.22s\n",
      "984:\tlearn: 0.3990169\ttotal: 3m 18s\tremaining: 3.02s\n",
      "985:\tlearn: 0.3981174\ttotal: 3m 18s\tremaining: 2.81s\n",
      "986:\tlearn: 0.3972439\ttotal: 3m 18s\tremaining: 2.61s\n",
      "987:\tlearn: 0.3966703\ttotal: 3m 18s\tremaining: 2.41s\n",
      "988:\tlearn: 0.3958645\ttotal: 3m 18s\tremaining: 2.21s\n",
      "989:\tlearn: 0.3953253\ttotal: 3m 18s\tremaining: 2.01s\n",
      "990:\tlearn: 0.3944044\ttotal: 3m 19s\tremaining: 1.81s\n",
      "991:\tlearn: 0.3939166\ttotal: 3m 19s\tremaining: 1.61s\n",
      "992:\tlearn: 0.3931429\ttotal: 3m 19s\tremaining: 1.41s\n",
      "993:\tlearn: 0.3924228\ttotal: 3m 19s\tremaining: 1.21s\n",
      "994:\tlearn: 0.3917302\ttotal: 3m 19s\tremaining: 1s\n",
      "995:\tlearn: 0.3910050\ttotal: 3m 20s\tremaining: 804ms\n",
      "996:\tlearn: 0.3905410\ttotal: 3m 20s\tremaining: 603ms\n",
      "997:\tlearn: 0.3894185\ttotal: 3m 20s\tremaining: 402ms\n",
      "998:\tlearn: 0.3889491\ttotal: 3m 20s\tremaining: 201ms\n",
      "999:\tlearn: 0.3885794\ttotal: 3m 20s\tremaining: 0us\n",
      "Suspected incorrect labels at indices: [2, 12, 29, 31, 38, 77, 81, 97, 102, 115, 116, 130, 131, 133, 136, 143, 146, 150, 153, 171, 180, 220, 221, 225, 231, 233, 244, 249, 270, 271, 274, 283, 303, 343, 355, 396, 409, 417, 424, 435, 467, 470, 492, 495, 496, 515, 545, 551, 560, 579, 585, 586, 589, 592, 598, 611, 617, 636, 654, 656, 664, 683, 688, 718, 721, 726, 754, 784, 788, 806, 812, 842, 855, 857, 862, 894, 900, 904, 924, 947, 960, 980, 994, 1011, 1012, 1017, 1020, 1023, 1024, 1025, 1034, 1040, 1045, 1057, 1061, 1081, 1086, 1121, 1122, 1138, 1151, 1156, 1178, 1207, 1211, 1224, 1240, 1243, 1246, 1255, 1262, 1267, 1286, 1302, 1315, 1334, 1336, 1358, 1366, 1367, 1392, 1405, 1427, 1461, 1465, 1474, 1504, 1513, 1517, 1521, 1522, 1530, 1534, 1585, 1587, 1604, 1608, 1614, 1615, 1619, 1625, 1646, 1649, 1652, 1656, 1657, 1665, 1674, 1677, 1708, 1736, 1740, 1795, 1800, 1803, 1807, 1810, 1831, 1845, 1851, 1861, 1869, 1876, 1877, 1886, 1893, 1898, 1900, 1930, 1953, 1954, 1967, 1994, 1999, 2020, 2029, 2034, 2050, 2055, 2056, 2065, 2066, 2086, 2095, 2105, 2120, 2122]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_43517/3440174449.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_weights = {'lgbm': 0.4, 'svm': 0.4, 'knn': 0.2}  # Adjust weights as needed\n",
    "\n",
    "# Function to fit models and make predictions (probabilities)\n",
    "def fit_and_predict(train_data, train_target, test_data):\n",
    "    # Train models\n",
    "    lgbm_model.fit(train_data, train_target)\n",
    "    svm_model.fit(train_data, train_target)\n",
    "    knn_model.fit(train_data, train_target)\n",
    "    \n",
    "    # Get predictions (probabilities) for each model\n",
    "    y_pred_lgbm = lgbm_model.predict_proba(test_data)\n",
    "    y_pred_svm = svm_model.predict_proba(test_data)\n",
    "    y_pred_knn = knn_model.predict_proba(test_data)\n",
    "    \n",
    "    # Weighted average of predictions\n",
    "    y_pred_weighted = (model_weights['lgbm'] * y_pred_lgbm +\n",
    "                       model_weights['svm'] * y_pred_svm +\n",
    "                       model_weights['knn'] * y_pred_knn)\n",
    "    \n",
    "    return y_pred_weighted\n",
    "\n",
    "# Function to remove mislabeled samples before training the models\n",
    "def remove_mislabeled_samples(train_data, train_target, incorrect_indices):\n",
    "    # Drop the mislabeled samples based on their indices\n",
    "    train_data_cleaned = train_data.drop(index=incorrect_indices)\n",
    "    train_target_cleaned = train_target.drop(index=incorrect_indices)\n",
    "    \n",
    "    return train_data_cleaned, train_target_cleaned\n",
    "\n",
    "# Remove mislabeled samples from the training data\n",
    "train_data_cleaned, train_target_cleaned = remove_mislabeled_samples(train.drop(columns='Target'), train['Target'], suspected_incorrect_labels)\n",
    "\n",
    "# Train the ensemble models on the cleaned data and make predictions on the test data\n",
    "y_pred_cleaned = fit_and_predict(train_data_cleaned, train_target_cleaned, test)\n",
    "\n",
    "# Apply threshold and rounding\n",
    "y_pred_cleaned = np.round(y_pred_cleaned, 1)\n",
    "mask = y_pred_cleaned >= 0.9\n",
    "y_pred_cleaned[~mask] = 0\n",
    "\n",
    "# Create the submission DataFrame\n",
    "class_labels = [f\"Target{i}\" for i in range(y_pred_cleaned.shape[1])]\n",
    "sub_df = pd.DataFrame(y_pred_cleaned, columns=class_labels)\n",
    "sub_df['id'] = test_id\n",
    "sub_df = sub_df[['id'] + class_labels]\n",
    "\n",
    "# Add missing columns if necessary\n",
    "all_target_labels = [f\"Target_{i}\" for i in range(125)]  # Adjust target classes accordingly\n",
    "for col in all_target_labels:\n",
    "    if col not in sub_df.columns:\n",
    "        sub_df[col] = 0\n",
    "\n",
    "# Save the submission file\n",
    "value = np.array(scores).mean()\n",
    "sub_df.to_csv(f\"../submissions/submissionr.csv\", index=False)\n",
    "\n",
    "# Output the indices of suspected mislabeled samples\n",
    "print(\"Suspected incorrect labels at indices:\", suspected_incorrect_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n",
      "/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_44793/3905899454.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sub_df[col] = 0  # Add missing targets and fill with 0\n"
     ]
    }
   ],
   "source": [
    "# Model weights for ensembling\n",
    "model_weights = {'lgbm': 0.5, 'svm': 0.3, 'knn': 0.2}\n",
    "\n",
    "# Function to train models and get predictions for test data\n",
    "def fit_and_predict(train_data, train_target, test_data):\n",
    "    with suppress_output():\n",
    "        # Train models\n",
    "        lgbm_model.fit(train_data, train_target)\n",
    "        svm_model.fit(train_data, train_target)\n",
    "        knn_model.fit(train_data, train_target)\n",
    "    \n",
    "    # Get predictions (probabilities) for each model\n",
    "    y_pred_lgbm = lgbm_model.predict_proba(test_data)\n",
    "    y_pred_svm = svm_model.predict_proba(test_data)\n",
    "    y_pred_knn = knn_model.predict_proba(test_data)\n",
    "    \n",
    "    # Weighted average of predictions\n",
    "    y_pred_weighted = (model_weights['lgbm'] * y_pred_lgbm +\n",
    "                       model_weights['svm'] * y_pred_svm +\n",
    "                       model_weights['knn'] * y_pred_knn)\n",
    "    \n",
    "    return y_pred_weighted\n",
    "\n",
    "# Encode target if necessary\n",
    "le = LabelEncoder()\n",
    "train['Target'] = le.fit_transform(train['Target'])\n",
    "\n",
    "\n",
    "value = np.mean(scores)\n",
    "\n",
    "# Final model training and prediction for submission\n",
    "y_pred = fit_and_predict(train.drop(columns='Target'), train['Target'], test)\n",
    "\n",
    "# Apply threshold and rounding\n",
    "y_pred = np.round(y_pred, 1)\n",
    "mask = y_pred >= 0.9\n",
    "y_pred[~mask] = 0\n",
    "\n",
    "# Create the submission DataFrame\n",
    "class_labels = [f\"Target{i}\" for i in range(y_pred.shape[1])]  \n",
    "sub_df = pd.DataFrame(y_pred, columns=class_labels)\n",
    "sub_df['id'] = test_id\n",
    "sub_df = sub_df[['id'] + class_labels]\n",
    "\n",
    "# Add missing columns (if any)\n",
    "all_target_labels = [f\"Target_{i}\" for i in range(125)]  # Up to Target_124\n",
    "for col in all_target_labels:\n",
    "    if col not in sub_df.columns:\n",
    "        sub_df[col] = 0  # Add missing targets and fill with 0\n",
    "\n",
    "# Save the submission file\n",
    "sub_df.to_csv(f\"../submissions/submission{value:.4f}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(f\"../submissions/submissionayo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['REFLEC1', 'REFLEC2', 'REFLEC3', 'REFLEC4', 'REFLEC5', 'REFLEC6',\n",
       "       'REFLEC7', 'PCA1', 'PCA2', 'PCA3', 'NDVI1', 'NDVI2', 'NDVI3', 'NDVI4',\n",
       "       'ELEV1', 'PEND1', 'ILUM1', 'TOPOIND1', 'ROUGH1', 'TRI1', 'COFS1',\n",
       "       'TMPMAN1', 'TMPMAX1', 'TMPMIN1', 'TVARDAY1', 'PRECIPAN1', 'PRECIPWET1',\n",
       "       'PRECIPDRY1', 'PRECIPVAR1', 'MARTONNE1', 'LAT2', 'LON1', 'DOSEL1',\n",
       "       'VVR1', 'VHR1', 'VHVVR1', 'VVD1', 'VHD1', 'MNDWI1', 'NDTI1', 'Target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '_init_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4c/h16036bx2ync7wqkqvrl2p1h0000gn/T/ipykernel_52686/3306899637.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvalue\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Target'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/computerscience/AI-Compeitions/INEGI-GCIM/vegitiables/lib/python3.11/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5236\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5237\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mCatBoost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5238\u001b[0m         \"\"\"\n\u001b[1;32m   5239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5240\u001b[0;31m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5241\u001b[0m         \u001b[0m_process_synonyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'loss_function'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5243\u001b[0m             \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/computerscience/AI-Compeitions/INEGI-GCIM/vegitiables/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '_init_params'"
     ]
    }
   ],
   "source": [
    "value  = np.array(scores).mean()\n",
    "model.fit(train.drop(columns='Target'),train['Target'])\n",
    "y_pred = model.predict_proba(test)\n",
    "y_pred = np.round(y_pred,1)\n",
    "mask = y_pred >= 0.9\n",
    "y_pred[~mask] = 0\n",
    "class_labels = [f\"Target{i}\" for i in range(y_pred.shape[1])]  \n",
    "sub_df = pd.DataFrame(y_pred, columns=class_labels)\n",
    "sub_df['id'] = test_id\n",
    "sub_df = sub_df[['id'] + class_labels]\n",
    "\n",
    "all_target_labels = [f\"Target_{i}\" for i in range(125)]  # Up to Target_124\n",
    "for col in all_target_labels:\n",
    "    if col not in sub_df.columns:\n",
    "        sub_df[col] = 0  \n",
    "#sub_df = pd.DataFrame({'id': test_id,'Target':y_pred})\n",
    "sub_df.to_csv(f\"../submissions/submissiona7a.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = model.feature_importances_\n",
    "names = model.feature_name_\n",
    "fi = pd.DataFrame({'Feature': names,\n",
    "                   'importances': importances})\n",
    "fi = fi.sort_values(by='importances', ascending=False)\n",
    "\n",
    "fi.plot(kind='bar', x='Feature', y='importances', legend=False, figsize=(20, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vegitiables",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
